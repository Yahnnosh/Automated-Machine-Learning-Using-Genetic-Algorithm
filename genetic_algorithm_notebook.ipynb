{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "activation_functions = {\n",
    "    'tanh': tf.tanh,\n",
    "    'relu': tf.nn.relu,\n",
    "    'sigmoid': tf.nn.sigmoid,\n",
    "    'linear': tf.keras.activations.linear,\n",
    "    'softmax': tf.nn.softmax,\n",
    "    'sign': tf.sign,\n",
    "    'sin': tf.sin,\n",
    "    'exp': tf.exp\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Loading Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "SUBSET = 1.0    # subset of X_test used during training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 234 ms\n",
      "Wall time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# numpy\n",
    "_, (X_test, y_test) = mnist.load_data() # only care  about X_test\n",
    "\n",
    "selection = np.random.choice(np.arange(X_test.shape[0]),\n",
    "                             int(SUBSET * X_test.shape[0]),\n",
    "                             replace=False)\n",
    "\n",
    "y_test = to_categorical(y_test[selection])  # one-hot encoding\n",
    "y_true = np.argmax(y_test, axis=1)  # store for faster evaluation\n",
    "\n",
    "# tensorflow\n",
    "X_test = tf.convert_to_tensor(X_test[selection].astype(np.float32) / 255.0)\n",
    "X_test = tf.reshape(X_test, shape=(X_test.shape[0],\n",
    "                                   X_test.shape[1],\n",
    "                                   X_test.shape[2],\n",
    "                                   1))\n",
    "y_test = tf.convert_to_tensor(np.transpose(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Network Definition**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TODO: BIAS AND ACTIVATION FUNCTION TO CONV**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "MUTATE_RATE_MATRIX = None               # init later\n",
    "MUTATE_RATE_BIAS = None                 # init later\n",
    "MUTATE_RATE_ACTIVATION_FUNCTION = None  # init later\n",
    "MUTATE_RATE_KERNEL = None               # init later\n",
    "CROSSOVER_RATE = None                   # init later\n",
    "GAUSSIAN_NOISE_STDDEV = None            # init later\n",
    "UNIFORM_CROSSOVER = None                # init later\n",
    "\n",
    "CONV_FILTER_SHAPE = None    # init later\n",
    "FILTER_STRIDES = None       # init later\n",
    "POOLING_STRIDES = None      # init later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def dimensions_in_conv_layers(*filters):\n",
    "    \"\"\"\n",
    "    Gets dimensions before and after each convolutional (with pooling) layer\n",
    "    :param filters: filter in convolutional layer\n",
    "    :param conv_strides: for each layer, filter strides - array\n",
    "    :return: list of dimensions (input_shape, output_shape)\n",
    "    \"\"\"\n",
    "    x = X_test[0:2, :, :, :]\n",
    "    batch_size, height, width, channels = x.shape\n",
    "    dimensions = [(height, width, channels)]\n",
    "\n",
    "    # convolutional layers\n",
    "    for filter, filter_stride, pooling_stride in zip(filters, FILTER_STRIDES, POOLING_STRIDES):\n",
    "        x = tf.nn.conv2d(x, filter, strides=[1, filter_stride, filter_stride, 1], padding='VALID')\n",
    "        if pooling_stride != 0:\n",
    "            x = tf.nn.max_pool2d(x, ksize=(2, 2), strides=(pooling_stride, pooling_stride), padding='VALID')\n",
    "        batch_size, height, width, channels = x.shape\n",
    "        dimensions.append((height, width, channels))\n",
    "\n",
    "    # flatten\n",
    "    x = tf.reshape(x, shape=(2, x.shape[-1] * x.shape[-2] * x.shape[-3]))\n",
    "    dimensions.append(x.shape[-1])\n",
    "    return dimensions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "    def __init__(self, **params):\n",
    "        \"\"\"\n",
    "        Convolutional neural network\n",
    "        :param params: matrix1, bias1, activation1, kernel1, etc.\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layers = max([int(param_name[-1]) if param_name[:-1] == 'kernel' else 0\n",
    "                                for param_name in params.keys()])\n",
    "        self.dense_layers = max([int(param_name[-1]) if param_name[:-1] == 'matrix' else 0\n",
    "                                 for param_name in params.keys()])   # = number of hidden layers + 1 (output layer)\n",
    "\n",
    "        for (param_name, param) in params.items():\n",
    "            assert param_name[:-1] in ('matrix', 'bias', 'activation', 'kernel'), 'Invalid attribute!'\n",
    "            setattr(self, param_name, param)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "\n",
    "        for layer in range(1, self.conv_layers + 1):\n",
    "            filter = getattr(self, 'kernel' + str(layer))\n",
    "            filter_stride = FILTER_STRIDES[layer - 1]\n",
    "            pooling_stride = POOLING_STRIDES[layer - 1]\n",
    "\n",
    "            # convolution\n",
    "            x = tf.nn.conv2d(x, filter,\n",
    "                             strides=[1, filter_stride, filter_stride, 1],\n",
    "                             padding='VALID')\n",
    "            # pooling\n",
    "            if pooling_stride != 0:\n",
    "                x = tf.nn.max_pool2d(x, ksize=(2, 2), strides=(pooling_stride, pooling_stride), padding='VALID')\n",
    "            # activation function # TODO: make mutable + bias\n",
    "            x = activation_functions['relu'](x)\n",
    "\n",
    "        # flatten\n",
    "        x = tf.reshape(x, shape=(inputs.shape[0], x.shape[-1] * x.shape[-2] * x.shape[-3]))\n",
    "\n",
    "        # fully connected layers\n",
    "        for layer in range(1, self.dense_layers + 1):\n",
    "            x @= getattr(self, 'matrix' + str(layer))\n",
    "            x += getattr(self, 'bias' + str(layer))\n",
    "            x = activation_functions[getattr(self, 'activation' + str(layer))](x) if layer != self.dense_layers else x\n",
    "\n",
    "        return x\n",
    "\n",
    "    def evaluate(self, mini_batch=1.0):\n",
    "        if mini_batch < 1.0:\n",
    "            selection = np.random.choice(np.arange(X_test.shape[0]),\n",
    "                                         int(mini_batch * X_test.shape[0]),\n",
    "                                         replace=False)\n",
    "            y_pred = np.argmax(self.call(X_test[selection]), axis=1)\n",
    "            return np.mean(y_pred == y_true[selection])\n",
    "        else:\n",
    "            y_pred = np.argmax(self.call(X_test), axis=1)\n",
    "            return np.mean(y_pred == y_true)\n",
    "\n",
    "    def mutate(self):\n",
    "        # convolutional layers\n",
    "        for layer in range(1, self.conv_layers + 1):\n",
    "            # kernel\n",
    "            kernel = getattr(self, 'kernel' + str(layer))\n",
    "            mutation_stencil = tf.cast(tf.reshape(tf.random.categorical(\n",
    "                tf.math.log([[1 - MUTATE_RATE_KERNEL, MUTATE_RATE_KERNEL]]),\n",
    "                kernel.shape[0] * kernel.shape[1] * kernel.shape[2] * kernel.shape[3]), kernel.shape), tf.float32)\n",
    "            noise = tf.random.normal(mean=0.0, stddev=GAUSSIAN_NOISE_STDDEV, shape=kernel.shape)\n",
    "            kernel = kernel + tf.multiply(mutation_stencil, noise)\n",
    "            setattr(self, 'kernel' + str(layer), kernel)\n",
    "\n",
    "        # fully connected layers\n",
    "        for layer in range(1, self.dense_layers + 1):\n",
    "            # matrix\n",
    "            matrix = getattr(self, 'matrix' + str(layer))\n",
    "            mutation_stencil = tf.cast(tf.reshape(tf.random.categorical(\n",
    "                tf.math.log([[1 - MUTATE_RATE_MATRIX, MUTATE_RATE_MATRIX]]),\n",
    "                matrix.shape[0] * matrix.shape[1]), matrix.shape), tf.float32)\n",
    "            noise = tf.random.normal(mean=0.0, stddev=GAUSSIAN_NOISE_STDDEV, shape=matrix.shape)\n",
    "            matrix = matrix + tf.multiply(mutation_stencil, noise)\n",
    "            setattr(self, 'matrix' + str(layer), matrix)\n",
    "\n",
    "            # bias\n",
    "            bias = getattr(self, 'bias' + str(layer))\n",
    "            mutation_stencil = tf.cast(tf.reshape(tf.random.categorical(\n",
    "                tf.math.log([[1 - MUTATE_RATE_BIAS, MUTATE_RATE_BIAS]]),\n",
    "                bias.shape[1]), bias.shape), tf.float32)\n",
    "            noise = tf.random.normal(mean=0.0, stddev=GAUSSIAN_NOISE_STDDEV, shape=bias.shape)\n",
    "            bias = bias + tf.multiply(mutation_stencil, noise)\n",
    "            setattr(self, 'bias' + str(layer), bias)\n",
    "\n",
    "            # activation\n",
    "            if layer != self.dense_layers:\n",
    "                cleaner = lambda x: 'softmax' if x=='softmax_v2' else x\n",
    "                activation = cleaner(getattr(self, 'activation' + str(layer)))\n",
    "                if random.uniform(0, 1) < MUTATE_RATE_ACTIVATION_FUNCTION:\n",
    "                    activation = random.choice(list(activation_functions.keys()))\n",
    "                setattr(self, 'activation' + str(layer), activation)\n",
    "\n",
    "    def summary(self):\n",
    "        dash = '-' * 90\n",
    "        ddash = '=' * 90\n",
    "        print(dash)\n",
    "        print('Model')\n",
    "        print(ddash)\n",
    "\n",
    "        n_params = 0\n",
    "\n",
    "        # convolutional layers\n",
    "        conv_IO = dimensions_in_conv_layers(*[getattr(self, 'kernel' + str(layer)) for layer in range(1, self.conv_layers + 1)])\n",
    "        for layer in range(1, self.conv_layers + 1):\n",
    "            # get values\n",
    "            kernel = getattr(self, 'kernel' + str(layer))\n",
    "\n",
    "            n_params += kernel.shape[0] * kernel.shape[1] * kernel.shape[2] * kernel.shape[3]\n",
    "            height_curr, width_curr, channels_curr = conv_IO[layer - 1]\n",
    "            height_next, width_next, channels_next = conv_IO[layer]\n",
    "\n",
    "            # print adjustments\n",
    "            layer_IO = '(in={}, out={})'.format((height_curr, width_curr, channels_curr), (height_next, width_next, channels_next))\n",
    "            pool = '' if POOLING_STRIDES[layer - 1] == 0 else '+ Pooling'\n",
    "            layer = 'Convolution {} {}'.format('(relu)', pool)\n",
    "\n",
    "            print('{:<30} {:<40} #Params: {}'.format(layer, layer_IO, kernel.shape[0] * kernel.shape[1] * kernel.shape[2] * kernel.shape[3]))\n",
    "\n",
    "        # flatten\n",
    "        height, width, channels = conv_IO[self.conv_layers]\n",
    "        layer_IO = '(in={}, out={})'.format((height, width, channels), (height * width * channels))\n",
    "        layer = 'Flatten ()'\n",
    "        print('{:<30} {:<40} #Params: {}'.format(layer, layer_IO, 0))\n",
    "\n",
    "        # fully connected layers\n",
    "        for layer in range(1, self.dense_layers + 1):\n",
    "            # get values\n",
    "            matrix = getattr(self, 'matrix' + str(layer))\n",
    "            bias = getattr(self, 'bias' + str(layer))\n",
    "            cleaner = lambda x: 'softmax' if x=='softmax_v2' else x\n",
    "            activation = cleaner(getattr(self, 'activation' + str(layer)))\n",
    "\n",
    "\n",
    "            n_params += matrix.shape[0] * matrix.shape[1] + bias.shape[0] * bias.shape[1] + 1\n",
    "\n",
    "            # print adjustments\n",
    "            activation = '({})'.format(activation)\n",
    "            layer_IO = '(in={}, out={})'.format(matrix.shape[0], matrix.shape[1],)\n",
    "            layer = 'Linear {}'.format(activation)\n",
    "\n",
    "            print('{:<30} {:<40} #Params: {}'.format(layer, layer_IO, matrix.shape[0] * matrix.shape[1] + bias.shape[0] * bias.shape[1] + 1))\n",
    "\n",
    "        print(ddash)\n",
    "        print('Total params: {}'.format(n_params))\n",
    "        print('Accuracy: {}\\n'.format(round(self.evaluate(), 3)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "class Population:\n",
    "    def __init__(self, size=10, n_survivors=5):\n",
    "        \"\"\"\n",
    "        :param size: population size\n",
    "        :param n_survivors: number of survivors after each generation (rest is killed and unable to pass on its genes)\n",
    "        :param n_hidden_layers: number of hidden layers\n",
    "        \"\"\"\n",
    "        self.generation = 0\n",
    "        self.size = size\n",
    "        self.n_survivors = n_survivors\n",
    "        self.elite = None\n",
    "        self.fitness = None # cache fitness for increased speed\n",
    "        self.fitness_generation = -1  # generation when fitness was evaluated\n",
    "        self.mini_batch = 1.0\n",
    "\n",
    "        # initialization (gaussian)\n",
    "        self.organisms = []\n",
    "        for _ in range(size):\n",
    "            params = {}\n",
    "\n",
    "            # convolutional layers\n",
    "            in_channels = X_test.shape[-1]\n",
    "            for layer in range(1, len(CONV_FILTER_SHAPE) + 1):\n",
    "                # filter shape: [filter_height, filter_width, in_channels, out_channels=n_filters]\n",
    "                filter_size = CONV_FILTER_SHAPE[layer - 1]\n",
    "                params['kernel' + str(layer)] = tf.random.normal(mean=0.0, stddev=1.0, shape=[filter_size[0],\n",
    "                                                                                              filter_size[1],\n",
    "                                                                                              in_channels,\n",
    "                                                                                              filter_size[2]])\n",
    "                in_channels = filter_size[2]\n",
    "\n",
    "            # fully connected layers\n",
    "            n_neurons_prev = dimensions_in_conv_layers(*list(params.values()))[-1]\n",
    "            n_neurons_curr = HIDDEN_LAYER_WIDTH[0]\n",
    "            activation = 'sigmoid'\n",
    "            for layer in range(1, N_HIDDEN_LAYERS + 2): # output layer\n",
    "                # output layer\n",
    "                if layer == N_HIDDEN_LAYERS + 1:\n",
    "                    n_neurons_curr = y_test.shape[0]\n",
    "                    activation = 'softmax'  # otherwise performance can decrease significantly (e.g. overflow)\n",
    "                else:\n",
    "                    n_neurons_curr = HIDDEN_LAYER_WIDTH[layer - 1]\n",
    "                params['matrix' + str(layer)] = tf.random.normal(mean=0.0, stddev=1.0, shape=[n_neurons_prev, n_neurons_curr])\n",
    "                params['bias' + str(layer)] = tf.random.normal(mean=0.0, stddev=1.0, shape=[1, n_neurons_curr])\n",
    "                params['activation' + str(layer)] = activation\n",
    "                n_neurons_prev = n_neurons_curr\n",
    "\n",
    "            model = CNN(**params)\n",
    "            self.organisms.append(model)\n",
    "\n",
    "        self.history = {'max': [self.max_fitness()],\n",
    "                        'min': [self.min_fitness()],\n",
    "                        'avg': [self.average_fitness()]} # fitness of population over all generations\n",
    "\n",
    "    def organism_fitness(self):\n",
    "        if self.generation != self.fitness_generation:\n",
    "            self.fitness = [organism.evaluate(mini_batch=self.mini_batch) for organism in self.organisms]\n",
    "            self.fitness_generation = self.generation\n",
    "\n",
    "        return self.fitness\n",
    "\n",
    "    def average_fitness(self):\n",
    "        organism_fitness = self.organism_fitness()\n",
    "        return sum(organism_fitness) / len(organism_fitness)\n",
    "\n",
    "    def max_fitness(self):\n",
    "        return max(self.organism_fitness())\n",
    "\n",
    "    def min_fitness(self):\n",
    "        return min(self.organism_fitness())\n",
    "\n",
    "    def selection(self):\n",
    "        organism_fitness = self.organism_fitness()\n",
    "\n",
    "        # elitism (n=1)\n",
    "        elite_index = np.argmax(organism_fitness)\n",
    "        self.elite = self.organisms.pop(elite_index)\n",
    "        organism_fitness.pop(elite_index)\n",
    "\n",
    "        probabilities = [fitness / sum(organism_fitness) for fitness in organism_fitness]  # normalized\n",
    "        survivors = np.random.choice(self.organisms,\n",
    "                                     size=self.n_survivors - 1,\n",
    "                                     p=probabilities,\n",
    "                                     replace=False)\n",
    "        return [survivor for survivor in survivors]\n",
    "\n",
    "    def crossover(self, parents):\n",
    "        children = []\n",
    "        while len(children) < int(CROSSOVER_RATE * (self.size - 1)):\n",
    "            [father, mother] = random.sample(parents + [self.elite], k=2)  # sample without replacement\n",
    "\n",
    "            child_params = {}\n",
    "\n",
    "            # convolutional layers\n",
    "            for layer in range(1, father.conv_layers + 1):\n",
    "                if UNIFORM_CROSSOVER:\n",
    "                    # kernel - uniform crossover\n",
    "                    father_kernel = getattr(father, 'kernel' + str(layer))\n",
    "                    mother_kernel = getattr(mother, 'kernel' + str(layer))\n",
    "\n",
    "                    father_mask = tf.round(tf.random.uniform(father_kernel.shape))\n",
    "                    mother_mask = - (father_mask - 1)\n",
    "\n",
    "                    child_kernel = tf.multiply(father_mask, father_kernel) + tf.multiply(mother_mask, mother_kernel)\n",
    "                    child_params['kernel' + str(layer)] = child_kernel\n",
    "                else:\n",
    "                    # kernel - filter-wise crossover\n",
    "                    father_kernel = getattr(father, 'kernel' + str(layer))\n",
    "                    mother_kernel = getattr(mother, 'kernel' + str(layer))\n",
    "\n",
    "                    filter_height, filter_width, in_channels, n_filters = father_kernel.shape\n",
    "                    father_mask = tf.zeros([filter_height, filter_width, in_channels, 1]) if random.uniform(0, 1) < 0.5 \\\n",
    "                        else tf.ones([filter_height, filter_width, in_channels, 1])\n",
    "                    for _ in range(n_filters - 1):\n",
    "                        filter_mask = tf.zeros([filter_height, filter_width, in_channels, 1]) if random.uniform(0, 1) < 0.5 \\\n",
    "                            else tf.ones([filter_height, filter_width, in_channels, 1])\n",
    "                        father_mask = tf.concat([father_mask, filter_mask], axis=-1)\n",
    "\n",
    "                    mother_mask = - (father_mask - 1)\n",
    "\n",
    "                    child_kernel = tf.multiply(father_mask, father_kernel) + tf.multiply(mother_mask, mother_kernel)\n",
    "                    child_params['kernel' + str(layer)] = child_kernel\n",
    "\n",
    "                    child_params['kernel' + str(layer)] = child_kernel\n",
    "\n",
    "            # fully connected layers\n",
    "            for layer in range(1, father.dense_layers + 1):\n",
    "                if UNIFORM_CROSSOVER:\n",
    "                    # matrix - uniform crossover\n",
    "                    father_matrix = getattr(father, 'matrix' + str(layer))\n",
    "                    mother_matrix = getattr(mother, 'matrix' + str(layer))\n",
    "\n",
    "                    father_mask = tf.round(tf.random.uniform(father_matrix.shape))\n",
    "                    mother_mask = - (father_mask - 1)\n",
    "\n",
    "                    child_matrix = tf.multiply(father_mask, father_matrix) + tf.multiply(mother_mask, mother_matrix)\n",
    "                    child_params['matrix' + str(layer)] = child_matrix\n",
    "                else:\n",
    "                    # matrix - column-wise (neuron-wise) crossover\n",
    "                    father_matrix = getattr(father, 'matrix' + str(layer))\n",
    "                    mother_matrix = getattr(mother, 'matrix' + str(layer))\n",
    "\n",
    "                    n_cols = father_matrix.shape[1]\n",
    "                    child_matrix = father_matrix.numpy()\n",
    "                    for col in range(n_cols):\n",
    "                        coin_toss = np.random.choice([True, False])\n",
    "                        if coin_toss:\n",
    "                            child_matrix[:, col] = mother_matrix[:, col]\n",
    "\n",
    "                    child_params['matrix' + str(layer)] = tf.convert_to_tensor(child_matrix)\n",
    "\n",
    "                # bias - uniform crossover\n",
    "                father_bias = getattr(father, 'bias' + str(layer))\n",
    "                mother_bias = getattr(mother, 'bias' + str(layer))\n",
    "\n",
    "                father_mask = tf.round(tf.random.uniform(father_bias.shape))\n",
    "                mother_mask = - (father_mask - 1)\n",
    "\n",
    "                child_bias = tf.multiply(father_mask, father_bias) + tf.multiply(mother_mask, mother_bias)\n",
    "                child_params['bias' + str(layer)] = child_bias\n",
    "\n",
    "                # activation\n",
    "                cleaner = lambda x: 'softmax' if x=='softmax_v2' else x\n",
    "                father_activation = cleaner(getattr(father, 'activation' + str(layer)))\n",
    "                mother_activation = cleaner(getattr(mother, 'activation' + str(layer)))\n",
    "\n",
    "                child_activation = father_activation if (random.uniform(0, 1) < 0.5) else mother_activation\n",
    "                child_params['activation' + str(layer)] = child_activation\n",
    "\n",
    "            model = CNN(**child_params)\n",
    "            children.append(model)\n",
    "\n",
    "        # if CROSSOVER_RATE != 100% allow some individuals to pass on their genes without crossover\n",
    "        while len(children) < (self.size - 1):\n",
    "            [model] = random.sample(parents + [self.elite], k=1)  # sample without replacement\n",
    "\n",
    "            child_params = {}\n",
    "\n",
    "            # convolutional layers\n",
    "            for layer in range(1, model.conv_layers + 1):\n",
    "                # kernel\n",
    "                child_params['kernel' + str(layer)] = tf.identity(getattr(model, 'kernel' + str(layer)))\n",
    "\n",
    "            # fully connnected layers\n",
    "            for layer in range(1, model.dense_layers + 1):\n",
    "                # matrix\n",
    "                child_params['matrix' + str(layer)] = tf.identity(getattr(model, 'matrix' + str(layer)))\n",
    "\n",
    "                # bias\n",
    "                child_params['bias' + str(layer)] = tf.identity(getattr(model, 'bias' + str(layer)))\n",
    "\n",
    "                # activation\n",
    "                cleaner = lambda x: 'softmax' if x=='softmax_v2' else x\n",
    "                child_params['activation' + str(layer)] = cleaner(getattr(model, 'activation' + str(layer)))\n",
    "\n",
    "            model = CNN(**child_params)\n",
    "            children.append(model)\n",
    "\n",
    "        return children\n",
    "\n",
    "    def mutate(self, organisms):\n",
    "        for organism in organisms:\n",
    "            organism.mutate()\n",
    "\n",
    "    def breed(self, debug=False):\n",
    "        if debug:\n",
    "            time_debug = ''\n",
    "\n",
    "            t_a = time.time()\n",
    "            parents = self.selection()  # ~0.0005s\n",
    "            t_b = time.time()\n",
    "            time_debug += 'selection time: {}s - '.format(round(t_b - t_a, 4))\n",
    "\n",
    "            t_a = time.time()\n",
    "            children = self.crossover(parents)  # ~0.28s\n",
    "            t_b = time.time()\n",
    "            time_debug += 'crossover time: {}s - '.format(round(t_b - t_a, 4))\n",
    "\n",
    "            t_a = time.time()\n",
    "            self.mutate(children)  # ~0.15s#\n",
    "            t_b = time.time()\n",
    "            time_debug += 'mutation time: {}s - '.format(round(t_b - t_a, 4))\n",
    "\n",
    "            print(time_debug)\n",
    "        else:\n",
    "            parents = self.selection()\n",
    "            children = self.crossover(parents)\n",
    "            self.mutate(children)\n",
    "\n",
    "        self.organisms = children + [self.elite]\n",
    "        self.generation += 1\n",
    "\n",
    "        # store data\n",
    "        max, min, avg = self.max_fitness(), self.min_fitness(), self.average_fitness()\n",
    "        self.history['max'].append(max)\n",
    "        self.history['min'].append(min)\n",
    "        self.history['avg'].append(avg)\n",
    "\n",
    "    def train(self, generations): # TODO: data storage vs self.history\n",
    "        # current population\n",
    "        print('Starting training')\n",
    "        t_training = time.time()\n",
    "\n",
    "        # evaluate initial population\n",
    "        max, min, avg = self.max_fitness(), self.min_fitness(), self.average_fitness()\n",
    "        t2 = time.time()\n",
    "\n",
    "        print('Gen {} {:<3} avg: {:.3f} {:^3} max: {:.3f} ({:<3}s)'.format(\n",
    "            self.generation, ':', round(avg, 3), '-', round(max, 3), round(t2 - t_training, 2)))\n",
    "\n",
    "        # future populations\n",
    "        for generation in range(1, generations):\n",
    "            # breed new population\n",
    "            t1 = time.time()\n",
    "            self.breed()\n",
    "\n",
    "            # evaluate new population\n",
    "            max, min, avg = self.max_fitness(), self.min_fitness(), self.average_fitness()\n",
    "\n",
    "            t2 = time.time()\n",
    "            print('Gen {} {:<3} avg: {:.3f} {:^3} max: {:.3f} ({:<3}s)'.format(\n",
    "                self.generation, ':', round(avg, 3), '-', round(max, 3), round(t2 - t1, 2)))\n",
    "\n",
    "        print('Finished training ({})'.format(round(time.time() - t_training, 2)))\n",
    "\n",
    "        # performance of population\n",
    "        self.plot()\n",
    "        plt.fill_between([i for i in range(len(self.history['max']))], self.history['max'], self.history['min'], color='orange', alpha=0.05)\n",
    "        plt.show()\n",
    "\n",
    "        # plot best performing final network\n",
    "        organism_fitness = self.organism_fitness()\n",
    "        elite_index = np.argmax(organism_fitness)\n",
    "        self.organisms[elite_index].summary()\n",
    "\n",
    "    def plot(self):\n",
    "        # plot evolution\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(self.generation + 1), self.history['max'], label='max fitness')\n",
    "        plt.plot(np.arange(self.generation + 1), self.history['avg'], label='avg fitness', alpha=0.6)\n",
    "        plt.title('Population fitness' + ' (n=' + str(self.size) + ')')\n",
    "        plt.xlabel('Generations')\n",
    "        plt.ylabel('Fitness score (accuracy)')\n",
    "        plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GA definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "global MUTATE_RATE_MATRIX\n",
    "global MUTATE_RATE_BIAS\n",
    "global MUTATE_RATE_ACTIVATION_FUNCTION\n",
    "global MUTATE_RATE_KERNEL\n",
    "global CROSSOVER_RATE\n",
    "global GAUSSIAN_NOISE_STDDEV\n",
    "global UNIFORM_CROSSOVER\n",
    "\n",
    "MUTATE_RATE_MATRIX = 1.0\n",
    "MUTATE_RATE_BIAS = 1.0\n",
    "MUTATE_RATE_ACTIVATION_FUNCTION = 1.0\n",
    "MUTATE_RATE_KERNEL = 1.0\n",
    "CROSSOVER_RATE = 0.0\n",
    "GAUSSIAN_NOISE_STDDEV = 0.5   # mutation applies additive gaussian noise\n",
    "UNIFORM_CROSSOVER = False   # if True, performs crossover of matrices/filters element-wise, else neuron-wise/filter-wise\n",
    "\n",
    "GENERATIONS = 1000\n",
    "POPULATION_SIZE = 10\n",
    "SURVIVORS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Network definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "global CONV_FILTER_SHAPE\n",
    "global FILTER_STRIDES\n",
    "global POOLING_STRIDES\n",
    "\n",
    "# convolutional layers\n",
    "CONV_FILTER_SHAPE = [(3, 3, 6)]     # [(filter_height, filter_width, n_filters), ...]\n",
    "FILTER_STRIDES = [1]\n",
    "POOLING_STRIDES = [2]               # 0 means no pooling layer after conv\n",
    "\n",
    "# fully connected layers\n",
    "N_HIDDEN_LAYERS = 0                 # fully connected hidden layers\n",
    "HIDDEN_LAYER_WIDTH = [64]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run GA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Gen 0 :   avg: 0.108  -  max: 0.149 (0.0s)\n",
      "Gen 1 :   avg: 0.136  -  max: 0.194 (0.12s)\n",
      "Gen 2 :   avg: 0.187  -  max: 0.224 (0.12s)\n",
      "Gen 3 :   avg: 0.191  -  max: 0.224 (0.13s)\n",
      "Gen 4 :   avg: 0.200  -  max: 0.224 (0.12s)\n",
      "Gen 5 :   avg: 0.202  -  max: 0.224 (0.12s)\n",
      "Gen 6 :   avg: 0.195  -  max: 0.237 (0.12s)\n",
      "Gen 7 :   avg: 0.231  -  max: 0.254 (0.12s)\n",
      "Gen 8 :   avg: 0.234  -  max: 0.260 (0.12s)\n",
      "Gen 9 :   avg: 0.236  -  max: 0.260 (0.12s)\n",
      "Gen 10 :   avg: 0.240  -  max: 0.282 (0.12s)\n",
      "Gen 11 :   avg: 0.257  -  max: 0.288 (0.12s)\n",
      "Gen 12 :   avg: 0.265  -  max: 0.288 (0.12s)\n",
      "Gen 13 :   avg: 0.275  -  max: 0.304 (0.12s)\n",
      "Gen 14 :   avg: 0.281  -  max: 0.310 (0.12s)\n",
      "Gen 15 :   avg: 0.287  -  max: 0.323 (0.12s)\n",
      "Gen 16 :   avg: 0.295  -  max: 0.333 (0.12s)\n",
      "Gen 17 :   avg: 0.314  -  max: 0.345 (0.12s)\n",
      "Gen 18 :   avg: 0.330  -  max: 0.345 (0.12s)\n",
      "Gen 19 :   avg: 0.333  -  max: 0.355 (0.12s)\n",
      "Gen 20 :   avg: 0.329  -  max: 0.355 (0.12s)\n",
      "Gen 21 :   avg: 0.338  -  max: 0.368 (0.12s)\n",
      "Gen 22 :   avg: 0.346  -  max: 0.370 (0.12s)\n",
      "Gen 23 :   avg: 0.343  -  max: 0.370 (0.12s)\n",
      "Gen 24 :   avg: 0.352  -  max: 0.370 (0.13s)\n",
      "Gen 25 :   avg: 0.346  -  max: 0.370 (0.12s)\n",
      "Gen 26 :   avg: 0.340  -  max: 0.370 (0.12s)\n",
      "Gen 27 :   avg: 0.354  -  max: 0.380 (0.11s)\n",
      "Gen 28 :   avg: 0.367  -  max: 0.390 (0.12s)\n",
      "Gen 29 :   avg: 0.362  -  max: 0.390 (0.12s)\n",
      "Gen 30 :   avg: 0.360  -  max: 0.399 (0.12s)\n",
      "Gen 31 :   avg: 0.359  -  max: 0.399 (0.12s)\n",
      "Gen 32 :   avg: 0.369  -  max: 0.399 (0.11s)\n",
      "Gen 33 :   avg: 0.379  -  max: 0.417 (0.12s)\n",
      "Gen 34 :   avg: 0.398  -  max: 0.417 (0.12s)\n",
      "Gen 35 :   avg: 0.392  -  max: 0.417 (0.11s)\n",
      "Gen 36 :   avg: 0.383  -  max: 0.417 (0.11s)\n",
      "Gen 37 :   avg: 0.382  -  max: 0.417 (0.12s)\n",
      "Gen 38 :   avg: 0.392  -  max: 0.421 (0.12s)\n",
      "Gen 39 :   avg: 0.394  -  max: 0.421 (0.12s)\n",
      "Gen 40 :   avg: 0.406  -  max: 0.430 (0.12s)\n",
      "Gen 41 :   avg: 0.402  -  max: 0.430 (0.12s)\n",
      "Gen 42 :   avg: 0.405  -  max: 0.430 (0.12s)\n",
      "Gen 43 :   avg: 0.408  -  max: 0.430 (0.12s)\n",
      "Gen 44 :   avg: 0.407  -  max: 0.438 (0.12s)\n",
      "Gen 45 :   avg: 0.416  -  max: 0.439 (0.12s)\n",
      "Gen 46 :   avg: 0.419  -  max: 0.446 (0.12s)\n",
      "Gen 47 :   avg: 0.426  -  max: 0.449 (0.12s)\n",
      "Gen 48 :   avg: 0.422  -  max: 0.449 (0.12s)\n",
      "Gen 49 :   avg: 0.433  -  max: 0.451 (0.12s)\n",
      "Gen 50 :   avg: 0.430  -  max: 0.451 (0.12s)\n",
      "Gen 51 :   avg: 0.432  -  max: 0.451 (0.12s)\n",
      "Gen 52 :   avg: 0.432  -  max: 0.463 (0.12s)\n",
      "Gen 53 :   avg: 0.447  -  max: 0.464 (0.12s)\n",
      "Gen 54 :   avg: 0.439  -  max: 0.464 (0.12s)\n",
      "Gen 55 :   avg: 0.449  -  max: 0.476 (0.12s)\n",
      "Gen 56 :   avg: 0.454  -  max: 0.478 (0.11s)\n",
      "Gen 57 :   avg: 0.456  -  max: 0.478 (0.12s)\n",
      "Gen 58 :   avg: 0.458  -  max: 0.478 (0.12s)\n",
      "Gen 59 :   avg: 0.455  -  max: 0.485 (0.12s)\n",
      "Gen 60 :   avg: 0.471  -  max: 0.491 (0.12s)\n",
      "Gen 61 :   avg: 0.469  -  max: 0.495 (0.12s)\n",
      "Gen 62 :   avg: 0.480  -  max: 0.495 (0.12s)\n",
      "Gen 63 :   avg: 0.477  -  max: 0.506 (0.11s)\n",
      "Gen 64 :   avg: 0.489  -  max: 0.506 (0.12s)\n",
      "Gen 65 :   avg: 0.484  -  max: 0.506 (0.12s)\n",
      "Gen 66 :   avg: 0.491  -  max: 0.506 (0.12s)\n",
      "Gen 67 :   avg: 0.496  -  max: 0.517 (0.12s)\n",
      "Gen 68 :   avg: 0.502  -  max: 0.518 (0.12s)\n",
      "Gen 69 :   avg: 0.501  -  max: 0.518 (0.13s)\n",
      "Gen 70 :   avg: 0.497  -  max: 0.518 (0.13s)\n",
      "Gen 71 :   avg: 0.501  -  max: 0.518 (0.12s)\n",
      "Gen 72 :   avg: 0.507  -  max: 0.526 (0.13s)\n",
      "Gen 73 :   avg: 0.507  -  max: 0.526 (0.12s)\n",
      "Gen 74 :   avg: 0.504  -  max: 0.534 (0.12s)\n",
      "Gen 75 :   avg: 0.521  -  max: 0.542 (0.12s)\n",
      "Gen 76 :   avg: 0.522  -  max: 0.542 (0.12s)\n",
      "Gen 77 :   avg: 0.523  -  max: 0.542 (0.12s)\n",
      "Gen 78 :   avg: 0.525  -  max: 0.550 (0.12s)\n",
      "Gen 79 :   avg: 0.536  -  max: 0.551 (0.12s)\n",
      "Gen 80 :   avg: 0.531  -  max: 0.551 (0.12s)\n",
      "Gen 81 :   avg: 0.541  -  max: 0.552 (0.12s)\n",
      "Gen 82 :   avg: 0.531  -  max: 0.552 (0.12s)\n",
      "Gen 83 :   avg: 0.536  -  max: 0.559 (0.12s)\n",
      "Gen 84 :   avg: 0.537  -  max: 0.559 (0.13s)\n",
      "Gen 85 :   avg: 0.544  -  max: 0.559 (0.12s)\n",
      "Gen 86 :   avg: 0.541  -  max: 0.566 (0.12s)\n",
      "Gen 87 :   avg: 0.550  -  max: 0.570 (0.12s)\n",
      "Gen 88 :   avg: 0.553  -  max: 0.583 (0.12s)\n",
      "Gen 89 :   avg: 0.558  -  max: 0.583 (0.12s)\n",
      "Gen 90 :   avg: 0.559  -  max: 0.583 (0.12s)\n",
      "Gen 91 :   avg: 0.564  -  max: 0.583 (0.12s)\n",
      "Gen 92 :   avg: 0.563  -  max: 0.590 (0.12s)\n",
      "Gen 93 :   avg: 0.570  -  max: 0.590 (0.12s)\n",
      "Gen 94 :   avg: 0.568  -  max: 0.590 (0.11s)\n",
      "Gen 95 :   avg: 0.562  -  max: 0.590 (0.11s)\n",
      "Gen 96 :   avg: 0.570  -  max: 0.590 (0.12s)\n",
      "Gen 97 :   avg: 0.568  -  max: 0.590 (0.11s)\n",
      "Gen 98 :   avg: 0.571  -  max: 0.590 (0.11s)\n",
      "Gen 99 :   avg: 0.560  -  max: 0.590 (0.12s)\n",
      "Gen 100 :   avg: 0.574  -  max: 0.590 (0.12s)\n",
      "Gen 101 :   avg: 0.570  -  max: 0.590 (0.11s)\n",
      "Gen 102 :   avg: 0.572  -  max: 0.593 (0.11s)\n",
      "Gen 103 :   avg: 0.572  -  max: 0.593 (0.11s)\n",
      "Gen 104 :   avg: 0.568  -  max: 0.593 (0.11s)\n",
      "Gen 105 :   avg: 0.578  -  max: 0.594 (0.12s)\n",
      "Gen 106 :   avg: 0.570  -  max: 0.594 (0.12s)\n",
      "Gen 107 :   avg: 0.569  -  max: 0.594 (0.11s)\n",
      "Gen 108 :   avg: 0.578  -  max: 0.594 (0.11s)\n",
      "Gen 109 :   avg: 0.572  -  max: 0.594 (0.12s)\n",
      "Gen 110 :   avg: 0.577  -  max: 0.594 (0.11s)\n",
      "Gen 111 :   avg: 0.567  -  max: 0.594 (0.11s)\n",
      "Gen 112 :   avg: 0.576  -  max: 0.594 (0.11s)\n",
      "Gen 113 :   avg: 0.575  -  max: 0.594 (0.12s)\n",
      "Gen 114 :   avg: 0.569  -  max: 0.596 (0.12s)\n",
      "Gen 115 :   avg: 0.574  -  max: 0.596 (0.12s)\n",
      "Gen 116 :   avg: 0.576  -  max: 0.596 (0.12s)\n",
      "Gen 117 :   avg: 0.575  -  max: 0.596 (0.11s)\n",
      "Gen 118 :   avg: 0.577  -  max: 0.599 (0.12s)\n",
      "Gen 119 :   avg: 0.583  -  max: 0.599 (0.12s)\n",
      "Gen 120 :   avg: 0.578  -  max: 0.599 (0.12s)\n",
      "Gen 121 :   avg: 0.588  -  max: 0.599 (0.11s)\n",
      "Gen 122 :   avg: 0.583  -  max: 0.599 (0.12s)\n",
      "Gen 123 :   avg: 0.579  -  max: 0.599 (0.12s)\n",
      "Gen 124 :   avg: 0.585  -  max: 0.600 (0.12s)\n",
      "Gen 125 :   avg: 0.586  -  max: 0.600 (0.12s)\n",
      "Gen 126 :   avg: 0.585  -  max: 0.606 (0.12s)\n",
      "Gen 127 :   avg: 0.589  -  max: 0.606 (0.12s)\n",
      "Gen 128 :   avg: 0.588  -  max: 0.606 (0.12s)\n",
      "Gen 129 :   avg: 0.589  -  max: 0.606 (0.11s)\n",
      "Gen 130 :   avg: 0.591  -  max: 0.606 (0.12s)\n",
      "Gen 131 :   avg: 0.589  -  max: 0.606 (0.12s)\n",
      "Gen 132 :   avg: 0.592  -  max: 0.610 (0.12s)\n",
      "Gen 133 :   avg: 0.592  -  max: 0.610 (0.12s)\n",
      "Gen 134 :   avg: 0.593  -  max: 0.610 (0.12s)\n",
      "Gen 135 :   avg: 0.592  -  max: 0.610 (0.12s)\n",
      "Gen 136 :   avg: 0.592  -  max: 0.610 (0.12s)\n",
      "Gen 137 :   avg: 0.591  -  max: 0.610 (0.13s)\n",
      "Gen 138 :   avg: 0.594  -  max: 0.610 (0.12s)\n",
      "Gen 139 :   avg: 0.595  -  max: 0.610 (0.12s)\n",
      "Gen 140 :   avg: 0.596  -  max: 0.610 (0.12s)\n",
      "Gen 141 :   avg: 0.589  -  max: 0.610 (0.12s)\n",
      "Gen 142 :   avg: 0.591  -  max: 0.610 (0.12s)\n",
      "Gen 143 :   avg: 0.601  -  max: 0.610 (0.12s)\n",
      "Gen 144 :   avg: 0.595  -  max: 0.610 (0.12s)\n",
      "Gen 145 :   avg: 0.593  -  max: 0.610 (0.11s)\n",
      "Gen 146 :   avg: 0.598  -  max: 0.612 (0.12s)\n",
      "Gen 147 :   avg: 0.597  -  max: 0.616 (0.12s)\n",
      "Gen 148 :   avg: 0.597  -  max: 0.616 (0.12s)\n",
      "Gen 149 :   avg: 0.607  -  max: 0.616 (0.12s)\n",
      "Gen 150 :   avg: 0.600  -  max: 0.616 (0.12s)\n",
      "Gen 151 :   avg: 0.597  -  max: 0.616 (0.12s)\n",
      "Gen 152 :   avg: 0.596  -  max: 0.616 (0.12s)\n",
      "Gen 153 :   avg: 0.600  -  max: 0.616 (0.12s)\n",
      "Gen 154 :   avg: 0.603  -  max: 0.616 (0.12s)\n",
      "Gen 155 :   avg: 0.599  -  max: 0.616 (0.12s)\n",
      "Gen 156 :   avg: 0.604  -  max: 0.616 (0.12s)\n",
      "Gen 157 :   avg: 0.601  -  max: 0.616 (0.12s)\n",
      "Gen 158 :   avg: 0.602  -  max: 0.617 (0.12s)\n",
      "Gen 159 :   avg: 0.609  -  max: 0.621 (0.12s)\n",
      "Gen 160 :   avg: 0.601  -  max: 0.621 (0.12s)\n",
      "Gen 161 :   avg: 0.606  -  max: 0.621 (0.13s)\n",
      "Gen 162 :   avg: 0.613  -  max: 0.623 (0.12s)\n",
      "Gen 163 :   avg: 0.613  -  max: 0.623 (0.12s)\n",
      "Gen 164 :   avg: 0.610  -  max: 0.623 (0.11s)\n",
      "Gen 165 :   avg: 0.609  -  max: 0.623 (0.11s)\n",
      "Gen 166 :   avg: 0.618  -  max: 0.632 (0.11s)\n",
      "Gen 167 :   avg: 0.619  -  max: 0.632 (0.12s)\n",
      "Gen 168 :   avg: 0.614  -  max: 0.632 (0.12s)\n",
      "Gen 169 :   avg: 0.614  -  max: 0.632 (0.12s)\n",
      "Gen 170 :   avg: 0.621  -  max: 0.632 (0.12s)\n",
      "Gen 171 :   avg: 0.615  -  max: 0.632 (0.12s)\n",
      "Gen 172 :   avg: 0.616  -  max: 0.632 (0.12s)\n",
      "Gen 173 :   avg: 0.623  -  max: 0.641 (0.12s)\n",
      "Gen 174 :   avg: 0.628  -  max: 0.641 (0.12s)\n",
      "Gen 175 :   avg: 0.623  -  max: 0.641 (0.12s)\n",
      "Gen 176 :   avg: 0.630  -  max: 0.641 (0.12s)\n",
      "Gen 177 :   avg: 0.628  -  max: 0.641 (0.12s)\n",
      "Gen 178 :   avg: 0.621  -  max: 0.641 (0.11s)\n",
      "Gen 179 :   avg: 0.630  -  max: 0.641 (0.11s)\n",
      "Gen 180 :   avg: 0.628  -  max: 0.641 (0.12s)\n",
      "Gen 181 :   avg: 0.624  -  max: 0.641 (0.12s)\n",
      "Gen 182 :   avg: 0.630  -  max: 0.641 (0.11s)\n",
      "Gen 183 :   avg: 0.628  -  max: 0.642 (0.11s)\n",
      "Gen 184 :   avg: 0.630  -  max: 0.644 (0.11s)\n",
      "Gen 185 :   avg: 0.636  -  max: 0.646 (0.11s)\n",
      "Gen 186 :   avg: 0.635  -  max: 0.646 (0.12s)\n",
      "Gen 187 :   avg: 0.636  -  max: 0.646 (0.12s)\n",
      "Gen 188 :   avg: 0.637  -  max: 0.646 (0.11s)\n",
      "Gen 189 :   avg: 0.633  -  max: 0.655 (0.12s)\n",
      "Gen 190 :   avg: 0.640  -  max: 0.655 (0.12s)\n",
      "Gen 191 :   avg: 0.641  -  max: 0.655 (0.11s)\n",
      "Gen 192 :   avg: 0.641  -  max: 0.655 (0.12s)\n",
      "Gen 193 :   avg: 0.640  -  max: 0.655 (0.12s)\n",
      "Gen 194 :   avg: 0.643  -  max: 0.657 (0.12s)\n",
      "Gen 195 :   avg: 0.649  -  max: 0.657 (0.12s)\n",
      "Gen 196 :   avg: 0.644  -  max: 0.657 (0.12s)\n",
      "Gen 197 :   avg: 0.650  -  max: 0.659 (0.11s)\n",
      "Gen 198 :   avg: 0.647  -  max: 0.659 (0.11s)\n",
      "Gen 199 :   avg: 0.650  -  max: 0.659 (0.11s)\n",
      "Gen 200 :   avg: 0.646  -  max: 0.659 (0.12s)\n",
      "Gen 201 :   avg: 0.649  -  max: 0.661 (0.12s)\n",
      "Gen 202 :   avg: 0.654  -  max: 0.661 (0.12s)\n",
      "Gen 203 :   avg: 0.647  -  max: 0.661 (0.11s)\n",
      "Gen 204 :   avg: 0.652  -  max: 0.661 (0.11s)\n",
      "Gen 205 :   avg: 0.645  -  max: 0.661 (0.12s)\n",
      "Gen 206 :   avg: 0.645  -  max: 0.661 (0.12s)\n",
      "Gen 207 :   avg: 0.649  -  max: 0.661 (0.12s)\n",
      "Gen 208 :   avg: 0.652  -  max: 0.665 (0.12s)\n",
      "Gen 209 :   avg: 0.653  -  max: 0.671 (0.12s)\n",
      "Gen 210 :   avg: 0.663  -  max: 0.675 (0.12s)\n",
      "Gen 211 :   avg: 0.661  -  max: 0.675 (0.12s)\n",
      "Gen 212 :   avg: 0.661  -  max: 0.675 (0.12s)\n",
      "Gen 213 :   avg: 0.660  -  max: 0.675 (0.12s)\n",
      "Gen 214 :   avg: 0.661  -  max: 0.675 (0.12s)\n",
      "Gen 215 :   avg: 0.668  -  max: 0.676 (0.12s)\n",
      "Gen 216 :   avg: 0.666  -  max: 0.676 (0.12s)\n",
      "Gen 217 :   avg: 0.665  -  max: 0.676 (0.12s)\n",
      "Gen 218 :   avg: 0.662  -  max: 0.676 (0.12s)\n",
      "Gen 219 :   avg: 0.666  -  max: 0.678 (0.12s)\n",
      "Gen 220 :   avg: 0.666  -  max: 0.678 (0.12s)\n",
      "Gen 221 :   avg: 0.664  -  max: 0.678 (0.12s)\n",
      "Gen 222 :   avg: 0.668  -  max: 0.678 (0.12s)\n",
      "Gen 223 :   avg: 0.665  -  max: 0.678 (0.12s)\n",
      "Gen 224 :   avg: 0.666  -  max: 0.678 (0.12s)\n",
      "Gen 225 :   avg: 0.666  -  max: 0.678 (0.12s)\n",
      "Gen 226 :   avg: 0.668  -  max: 0.678 (0.12s)\n",
      "Gen 227 :   avg: 0.663  -  max: 0.678 (0.12s)\n",
      "Gen 228 :   avg: 0.667  -  max: 0.678 (0.12s)\n",
      "Gen 229 :   avg: 0.664  -  max: 0.678 (0.12s)\n",
      "Gen 230 :   avg: 0.666  -  max: 0.678 (0.12s)\n",
      "Gen 231 :   avg: 0.669  -  max: 0.679 (0.11s)\n",
      "Gen 232 :   avg: 0.668  -  max: 0.679 (0.11s)\n",
      "Gen 233 :   avg: 0.667  -  max: 0.681 (0.12s)\n",
      "Gen 234 :   avg: 0.664  -  max: 0.681 (0.11s)\n",
      "Gen 235 :   avg: 0.673  -  max: 0.684 (0.11s)\n",
      "Gen 236 :   avg: 0.674  -  max: 0.684 (0.12s)\n",
      "Gen 237 :   avg: 0.674  -  max: 0.687 (0.12s)\n",
      "Gen 238 :   avg: 0.670  -  max: 0.687 (0.12s)\n",
      "Gen 239 :   avg: 0.675  -  max: 0.687 (0.12s)\n",
      "Gen 240 :   avg: 0.671  -  max: 0.687 (0.12s)\n",
      "Gen 241 :   avg: 0.672  -  max: 0.687 (0.12s)\n",
      "Gen 242 :   avg: 0.671  -  max: 0.687 (0.11s)\n",
      "Gen 243 :   avg: 0.672  -  max: 0.687 (0.11s)\n",
      "Gen 244 :   avg: 0.676  -  max: 0.687 (0.11s)\n",
      "Gen 245 :   avg: 0.675  -  max: 0.687 (0.11s)\n",
      "Gen 246 :   avg: 0.677  -  max: 0.687 (0.11s)\n",
      "Gen 247 :   avg: 0.674  -  max: 0.687 (0.11s)\n",
      "Gen 248 :   avg: 0.678  -  max: 0.687 (0.11s)\n",
      "Gen 249 :   avg: 0.676  -  max: 0.687 (0.12s)\n",
      "Gen 250 :   avg: 0.679  -  max: 0.690 (0.11s)\n",
      "Gen 251 :   avg: 0.682  -  max: 0.694 (0.11s)\n",
      "Gen 252 :   avg: 0.686  -  max: 0.694 (0.12s)\n",
      "Gen 253 :   avg: 0.686  -  max: 0.694 (0.12s)\n",
      "Gen 254 :   avg: 0.685  -  max: 0.694 (0.11s)\n",
      "Gen 255 :   avg: 0.684  -  max: 0.694 (0.12s)\n",
      "Gen 256 :   avg: 0.682  -  max: 0.694 (0.11s)\n",
      "Gen 257 :   avg: 0.685  -  max: 0.694 (0.11s)\n",
      "Gen 258 :   avg: 0.687  -  max: 0.695 (0.12s)\n",
      "Gen 259 :   avg: 0.683  -  max: 0.695 (0.12s)\n",
      "Gen 260 :   avg: 0.687  -  max: 0.695 (0.12s)\n",
      "Gen 261 :   avg: 0.684  -  max: 0.695 (0.11s)\n",
      "Gen 262 :   avg: 0.682  -  max: 0.695 (0.11s)\n",
      "Gen 263 :   avg: 0.686  -  max: 0.695 (0.12s)\n",
      "Gen 264 :   avg: 0.684  -  max: 0.695 (0.12s)\n",
      "Gen 265 :   avg: 0.686  -  max: 0.695 (0.12s)\n",
      "Gen 266 :   avg: 0.686  -  max: 0.702 (0.12s)\n",
      "Gen 267 :   avg: 0.689  -  max: 0.702 (0.11s)\n",
      "Gen 268 :   avg: 0.692  -  max: 0.702 (0.11s)\n",
      "Gen 269 :   avg: 0.691  -  max: 0.702 (0.12s)\n",
      "Gen 270 :   avg: 0.693  -  max: 0.702 (0.12s)\n",
      "Gen 271 :   avg: 0.697  -  max: 0.705 (0.11s)\n",
      "Gen 272 :   avg: 0.690  -  max: 0.705 (0.12s)\n",
      "Gen 273 :   avg: 0.694  -  max: 0.705 (0.12s)\n",
      "Gen 274 :   avg: 0.693  -  max: 0.709 (0.12s)\n",
      "Gen 275 :   avg: 0.694  -  max: 0.709 (0.12s)\n",
      "Gen 276 :   avg: 0.699  -  max: 0.709 (0.12s)\n",
      "Gen 277 :   avg: 0.700  -  max: 0.709 (0.12s)\n",
      "Gen 278 :   avg: 0.697  -  max: 0.709 (0.12s)\n",
      "Gen 279 :   avg: 0.699  -  max: 0.709 (0.12s)\n",
      "Gen 280 :   avg: 0.699  -  max: 0.709 (0.12s)\n",
      "Gen 281 :   avg: 0.698  -  max: 0.709 (0.12s)\n",
      "Gen 282 :   avg: 0.706  -  max: 0.712 (0.11s)\n",
      "Gen 283 :   avg: 0.699  -  max: 0.712 (0.12s)\n",
      "Gen 284 :   avg: 0.703  -  max: 0.712 (0.12s)\n",
      "Gen 285 :   avg: 0.703  -  max: 0.712 (0.12s)\n",
      "Gen 286 :   avg: 0.700  -  max: 0.712 (0.13s)\n",
      "Gen 287 :   avg: 0.701  -  max: 0.712 (0.12s)\n",
      "Gen 288 :   avg: 0.703  -  max: 0.712 (0.12s)\n",
      "Gen 289 :   avg: 0.701  -  max: 0.712 (0.12s)\n",
      "Gen 290 :   avg: 0.700  -  max: 0.712 (0.12s)\n",
      "Gen 291 :   avg: 0.700  -  max: 0.712 (0.12s)\n",
      "Gen 292 :   avg: 0.703  -  max: 0.713 (0.12s)\n",
      "Gen 293 :   avg: 0.706  -  max: 0.713 (0.12s)\n",
      "Gen 294 :   avg: 0.704  -  max: 0.713 (0.12s)\n",
      "Gen 295 :   avg: 0.702  -  max: 0.713 (0.12s)\n",
      "Gen 296 :   avg: 0.699  -  max: 0.713 (0.12s)\n",
      "Gen 297 :   avg: 0.703  -  max: 0.713 (0.12s)\n",
      "Gen 298 :   avg: 0.702  -  max: 0.713 (0.12s)\n",
      "Gen 299 :   avg: 0.699  -  max: 0.713 (0.11s)\n",
      "Gen 300 :   avg: 0.704  -  max: 0.713 (0.11s)\n",
      "Gen 301 :   avg: 0.701  -  max: 0.713 (0.11s)\n",
      "Gen 302 :   avg: 0.698  -  max: 0.713 (0.12s)\n",
      "Gen 303 :   avg: 0.699  -  max: 0.713 (0.11s)\n",
      "Gen 304 :   avg: 0.701  -  max: 0.713 (0.12s)\n",
      "Gen 305 :   avg: 0.702  -  max: 0.713 (0.12s)\n",
      "Gen 306 :   avg: 0.699  -  max: 0.713 (0.11s)\n",
      "Gen 307 :   avg: 0.702  -  max: 0.713 (0.12s)\n",
      "Gen 308 :   avg: 0.698  -  max: 0.713 (0.11s)\n",
      "Gen 309 :   avg: 0.707  -  max: 0.714 (0.12s)\n",
      "Gen 310 :   avg: 0.704  -  max: 0.714 (0.12s)\n",
      "Gen 311 :   avg: 0.698  -  max: 0.714 (0.12s)\n",
      "Gen 312 :   avg: 0.700  -  max: 0.714 (0.11s)\n",
      "Gen 313 :   avg: 0.703  -  max: 0.714 (0.12s)\n",
      "Gen 314 :   avg: 0.700  -  max: 0.714 (0.11s)\n",
      "Gen 315 :   avg: 0.702  -  max: 0.714 (0.12s)\n",
      "Gen 316 :   avg: 0.702  -  max: 0.714 (0.12s)\n",
      "Gen 317 :   avg: 0.703  -  max: 0.714 (0.11s)\n",
      "Gen 318 :   avg: 0.701  -  max: 0.714 (0.12s)\n",
      "Gen 319 :   avg: 0.699  -  max: 0.714 (0.12s)\n",
      "Gen 320 :   avg: 0.702  -  max: 0.714 (0.12s)\n",
      "Gen 321 :   avg: 0.704  -  max: 0.714 (0.11s)\n",
      "Gen 322 :   avg: 0.700  -  max: 0.714 (0.11s)\n",
      "Gen 323 :   avg: 0.699  -  max: 0.714 (0.11s)\n",
      "Gen 324 :   avg: 0.700  -  max: 0.714 (0.11s)\n",
      "Gen 325 :   avg: 0.705  -  max: 0.715 (0.11s)\n",
      "Gen 326 :   avg: 0.707  -  max: 0.715 (0.11s)\n",
      "Gen 327 :   avg: 0.706  -  max: 0.715 (0.12s)\n",
      "Gen 328 :   avg: 0.704  -  max: 0.715 (0.11s)\n",
      "Gen 329 :   avg: 0.706  -  max: 0.715 (0.11s)\n",
      "Gen 330 :   avg: 0.707  -  max: 0.715 (0.11s)\n",
      "Gen 331 :   avg: 0.705  -  max: 0.715 (0.11s)\n",
      "Gen 332 :   avg: 0.706  -  max: 0.715 (0.11s)\n",
      "Gen 333 :   avg: 0.707  -  max: 0.715 (0.12s)\n",
      "Gen 334 :   avg: 0.707  -  max: 0.716 (0.12s)\n",
      "Gen 335 :   avg: 0.709  -  max: 0.716 (0.11s)\n",
      "Gen 336 :   avg: 0.707  -  max: 0.716 (0.11s)\n",
      "Gen 337 :   avg: 0.708  -  max: 0.716 (0.11s)\n",
      "Gen 338 :   avg: 0.708  -  max: 0.716 (0.11s)\n",
      "Gen 339 :   avg: 0.708  -  max: 0.716 (0.11s)\n",
      "Gen 340 :   avg: 0.707  -  max: 0.716 (0.11s)\n",
      "Gen 341 :   avg: 0.713  -  max: 0.722 (0.12s)\n",
      "Gen 342 :   avg: 0.713  -  max: 0.722 (0.12s)\n",
      "Gen 343 :   avg: 0.712  -  max: 0.722 (0.12s)\n",
      "Gen 344 :   avg: 0.714  -  max: 0.723 (0.12s)\n",
      "Gen 345 :   avg: 0.710  -  max: 0.723 (0.12s)\n",
      "Gen 346 :   avg: 0.714  -  max: 0.724 (0.12s)\n",
      "Gen 347 :   avg: 0.718  -  max: 0.724 (0.12s)\n",
      "Gen 348 :   avg: 0.718  -  max: 0.726 (0.12s)\n",
      "Gen 349 :   avg: 0.716  -  max: 0.726 (0.12s)\n",
      "Gen 350 :   avg: 0.713  -  max: 0.726 (0.12s)\n",
      "Gen 351 :   avg: 0.720  -  max: 0.728 (0.12s)\n",
      "Gen 352 :   avg: 0.715  -  max: 0.728 (0.12s)\n",
      "Gen 353 :   avg: 0.719  -  max: 0.728 (0.12s)\n",
      "Gen 354 :   avg: 0.718  -  max: 0.728 (0.12s)\n",
      "Gen 355 :   avg: 0.714  -  max: 0.728 (0.12s)\n",
      "Gen 356 :   avg: 0.717  -  max: 0.728 (0.12s)\n",
      "Gen 357 :   avg: 0.719  -  max: 0.728 (0.12s)\n",
      "Gen 358 :   avg: 0.719  -  max: 0.728 (0.12s)\n",
      "Gen 359 :   avg: 0.716  -  max: 0.732 (0.13s)\n",
      "Gen 360 :   avg: 0.722  -  max: 0.732 (0.12s)\n",
      "Gen 361 :   avg: 0.725  -  max: 0.732 (0.13s)\n",
      "Gen 362 :   avg: 0.722  -  max: 0.732 (0.12s)\n",
      "Gen 363 :   avg: 0.722  -  max: 0.732 (0.12s)\n",
      "Gen 364 :   avg: 0.721  -  max: 0.732 (0.13s)\n",
      "Gen 365 :   avg: 0.721  -  max: 0.732 (0.12s)\n",
      "Gen 366 :   avg: 0.719  -  max: 0.732 (0.12s)\n",
      "Gen 367 :   avg: 0.721  -  max: 0.732 (0.12s)\n",
      "Gen 368 :   avg: 0.724  -  max: 0.734 (0.12s)\n",
      "Gen 369 :   avg: 0.725  -  max: 0.734 (0.11s)\n",
      "Gen 370 :   avg: 0.725  -  max: 0.734 (0.11s)\n",
      "Gen 371 :   avg: 0.725  -  max: 0.734 (0.11s)\n",
      "Gen 372 :   avg: 0.725  -  max: 0.734 (0.11s)\n",
      "Gen 373 :   avg: 0.727  -  max: 0.734 (0.11s)\n",
      "Gen 374 :   avg: 0.726  -  max: 0.734 (0.12s)\n",
      "Gen 375 :   avg: 0.726  -  max: 0.734 (0.11s)\n",
      "Gen 376 :   avg: 0.724  -  max: 0.734 (0.11s)\n",
      "Gen 377 :   avg: 0.723  -  max: 0.734 (0.11s)\n",
      "Gen 378 :   avg: 0.727  -  max: 0.734 (0.11s)\n",
      "Gen 379 :   avg: 0.724  -  max: 0.734 (0.11s)\n",
      "Gen 380 :   avg: 0.726  -  max: 0.734 (0.11s)\n",
      "Gen 381 :   avg: 0.722  -  max: 0.734 (0.11s)\n",
      "Gen 382 :   avg: 0.726  -  max: 0.734 (0.11s)\n",
      "Gen 383 :   avg: 0.727  -  max: 0.734 (0.12s)\n",
      "Gen 384 :   avg: 0.726  -  max: 0.734 (0.11s)\n",
      "Gen 385 :   avg: 0.725  -  max: 0.734 (0.11s)\n",
      "Gen 386 :   avg: 0.723  -  max: 0.734 (0.11s)\n",
      "Gen 387 :   avg: 0.725  -  max: 0.734 (0.11s)\n",
      "Gen 388 :   avg: 0.725  -  max: 0.735 (0.11s)\n",
      "Gen 389 :   avg: 0.725  -  max: 0.735 (0.12s)\n",
      "Gen 390 :   avg: 0.726  -  max: 0.735 (0.11s)\n",
      "Gen 391 :   avg: 0.728  -  max: 0.735 (0.11s)\n",
      "Gen 392 :   avg: 0.728  -  max: 0.735 (0.11s)\n",
      "Gen 393 :   avg: 0.725  -  max: 0.735 (0.12s)\n",
      "Gen 394 :   avg: 0.725  -  max: 0.735 (0.12s)\n",
      "Gen 395 :   avg: 0.727  -  max: 0.735 (0.11s)\n",
      "Gen 396 :   avg: 0.729  -  max: 0.735 (0.11s)\n",
      "Gen 397 :   avg: 0.723  -  max: 0.737 (0.11s)\n",
      "Gen 398 :   avg: 0.725  -  max: 0.737 (0.11s)\n",
      "Gen 399 :   avg: 0.728  -  max: 0.737 (0.12s)\n",
      "Gen 400 :   avg: 0.726  -  max: 0.737 (0.11s)\n",
      "Gen 401 :   avg: 0.726  -  max: 0.737 (0.11s)\n",
      "Gen 402 :   avg: 0.729  -  max: 0.738 (0.12s)\n",
      "Gen 403 :   avg: 0.730  -  max: 0.738 (0.11s)\n",
      "Gen 404 :   avg: 0.731  -  max: 0.739 (0.12s)\n",
      "Gen 405 :   avg: 0.730  -  max: 0.739 (0.11s)\n",
      "Gen 406 :   avg: 0.730  -  max: 0.739 (0.11s)\n",
      "Gen 407 :   avg: 0.728  -  max: 0.740 (0.11s)\n",
      "Gen 408 :   avg: 0.729  -  max: 0.740 (0.12s)\n",
      "Gen 409 :   avg: 0.728  -  max: 0.740 (0.12s)\n",
      "Gen 410 :   avg: 0.732  -  max: 0.740 (0.12s)\n",
      "Gen 411 :   avg: 0.731  -  max: 0.741 (0.12s)\n",
      "Gen 412 :   avg: 0.732  -  max: 0.744 (0.12s)\n",
      "Gen 413 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 414 :   avg: 0.732  -  max: 0.744 (0.13s)\n",
      "Gen 415 :   avg: 0.733  -  max: 0.744 (0.13s)\n",
      "Gen 416 :   avg: 0.735  -  max: 0.744 (0.12s)\n",
      "Gen 417 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 418 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 419 :   avg: 0.732  -  max: 0.744 (0.12s)\n",
      "Gen 420 :   avg: 0.734  -  max: 0.744 (0.12s)\n",
      "Gen 421 :   avg: 0.735  -  max: 0.744 (0.12s)\n",
      "Gen 422 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 423 :   avg: 0.730  -  max: 0.744 (0.12s)\n",
      "Gen 424 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 425 :   avg: 0.732  -  max: 0.744 (0.12s)\n",
      "Gen 426 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 427 :   avg: 0.735  -  max: 0.744 (0.12s)\n",
      "Gen 428 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 429 :   avg: 0.737  -  max: 0.744 (0.12s)\n",
      "Gen 430 :   avg: 0.734  -  max: 0.744 (0.12s)\n",
      "Gen 431 :   avg: 0.731  -  max: 0.744 (0.12s)\n",
      "Gen 432 :   avg: 0.736  -  max: 0.744 (0.12s)\n",
      "Gen 433 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 434 :   avg: 0.736  -  max: 0.744 (0.12s)\n",
      "Gen 435 :   avg: 0.734  -  max: 0.744 (0.12s)\n",
      "Gen 436 :   avg: 0.736  -  max: 0.744 (0.12s)\n",
      "Gen 437 :   avg: 0.732  -  max: 0.744 (0.11s)\n",
      "Gen 438 :   avg: 0.734  -  max: 0.744 (0.12s)\n",
      "Gen 439 :   avg: 0.733  -  max: 0.744 (0.11s)\n",
      "Gen 440 :   avg: 0.736  -  max: 0.744 (0.12s)\n",
      "Gen 441 :   avg: 0.731  -  max: 0.744 (0.12s)\n",
      "Gen 442 :   avg: 0.732  -  max: 0.744 (0.12s)\n",
      "Gen 443 :   avg: 0.735  -  max: 0.744 (0.12s)\n",
      "Gen 444 :   avg: 0.737  -  max: 0.744 (0.11s)\n",
      "Gen 445 :   avg: 0.734  -  max: 0.744 (0.12s)\n",
      "Gen 446 :   avg: 0.732  -  max: 0.744 (0.12s)\n",
      "Gen 447 :   avg: 0.733  -  max: 0.744 (0.12s)\n",
      "Gen 448 :   avg: 0.734  -  max: 0.744 (0.11s)\n",
      "Gen 449 :   avg: 0.736  -  max: 0.744 (0.12s)\n",
      "Gen 450 :   avg: 0.735  -  max: 0.744 (0.12s)\n",
      "Gen 451 :   avg: 0.734  -  max: 0.744 (0.12s)\n",
      "Gen 452 :   avg: 0.737  -  max: 0.749 (0.11s)\n",
      "Gen 453 :   avg: 0.737  -  max: 0.749 (0.12s)\n",
      "Gen 454 :   avg: 0.740  -  max: 0.749 (0.12s)\n",
      "Gen 455 :   avg: 0.737  -  max: 0.749 (0.12s)\n",
      "Gen 456 :   avg: 0.741  -  max: 0.749 (0.12s)\n",
      "Gen 457 :   avg: 0.741  -  max: 0.749 (0.12s)\n",
      "Gen 458 :   avg: 0.737  -  max: 0.749 (0.12s)\n",
      "Gen 459 :   avg: 0.738  -  max: 0.749 (0.12s)\n",
      "Gen 460 :   avg: 0.739  -  max: 0.749 (0.12s)\n",
      "Gen 461 :   avg: 0.739  -  max: 0.749 (0.13s)\n",
      "Gen 462 :   avg: 0.741  -  max: 0.749 (0.12s)\n",
      "Gen 463 :   avg: 0.740  -  max: 0.749 (0.11s)\n",
      "Gen 464 :   avg: 0.738  -  max: 0.749 (0.12s)\n",
      "Gen 465 :   avg: 0.741  -  max: 0.749 (0.12s)\n",
      "Gen 466 :   avg: 0.738  -  max: 0.749 (0.12s)\n",
      "Gen 467 :   avg: 0.740  -  max: 0.749 (0.12s)\n",
      "Gen 468 :   avg: 0.739  -  max: 0.749 (0.12s)\n",
      "Gen 469 :   avg: 0.735  -  max: 0.749 (0.11s)\n",
      "Gen 470 :   avg: 0.741  -  max: 0.749 (0.12s)\n",
      "Gen 471 :   avg: 0.741  -  max: 0.749 (0.11s)\n",
      "Gen 472 :   avg: 0.735  -  max: 0.749 (0.12s)\n",
      "Gen 473 :   avg: 0.739  -  max: 0.749 (0.11s)\n",
      "Gen 474 :   avg: 0.737  -  max: 0.749 (0.12s)\n",
      "Gen 475 :   avg: 0.735  -  max: 0.749 (0.12s)\n",
      "Gen 476 :   avg: 0.735  -  max: 0.749 (0.12s)\n",
      "Gen 477 :   avg: 0.739  -  max: 0.749 (0.12s)\n",
      "Gen 478 :   avg: 0.741  -  max: 0.749 (0.12s)\n",
      "Gen 479 :   avg: 0.736  -  max: 0.749 (0.12s)\n",
      "Gen 480 :   avg: 0.740  -  max: 0.749 (0.12s)\n",
      "Gen 481 :   avg: 0.740  -  max: 0.749 (0.12s)\n",
      "Gen 482 :   avg: 0.740  -  max: 0.749 (0.12s)\n",
      "Gen 483 :   avg: 0.737  -  max: 0.749 (0.12s)\n",
      "Gen 484 :   avg: 0.736  -  max: 0.749 (0.12s)\n",
      "Gen 485 :   avg: 0.740  -  max: 0.751 (0.12s)\n",
      "Gen 486 :   avg: 0.741  -  max: 0.751 (0.12s)\n",
      "Gen 487 :   avg: 0.738  -  max: 0.754 (0.12s)\n",
      "Gen 488 :   avg: 0.745  -  max: 0.754 (0.12s)\n",
      "Gen 489 :   avg: 0.742  -  max: 0.754 (0.12s)\n",
      "Gen 490 :   avg: 0.744  -  max: 0.754 (0.12s)\n",
      "Gen 491 :   avg: 0.741  -  max: 0.754 (0.12s)\n",
      "Gen 492 :   avg: 0.743  -  max: 0.754 (0.12s)\n",
      "Gen 493 :   avg: 0.742  -  max: 0.754 (0.12s)\n",
      "Gen 494 :   avg: 0.743  -  max: 0.754 (0.12s)\n",
      "Gen 495 :   avg: 0.744  -  max: 0.754 (0.12s)\n",
      "Gen 496 :   avg: 0.744  -  max: 0.754 (0.12s)\n",
      "Gen 497 :   avg: 0.743  -  max: 0.754 (0.12s)\n",
      "Gen 498 :   avg: 0.745  -  max: 0.754 (0.12s)\n",
      "Gen 499 :   avg: 0.746  -  max: 0.755 (0.12s)\n",
      "Gen 500 :   avg: 0.747  -  max: 0.755 (0.12s)\n",
      "Gen 501 :   avg: 0.748  -  max: 0.760 (0.12s)\n",
      "Gen 502 :   avg: 0.747  -  max: 0.760 (0.12s)\n",
      "Gen 503 :   avg: 0.749  -  max: 0.760 (0.12s)\n",
      "Gen 504 :   avg: 0.748  -  max: 0.760 (0.12s)\n",
      "Gen 505 :   avg: 0.750  -  max: 0.760 (0.12s)\n",
      "Gen 506 :   avg: 0.751  -  max: 0.760 (0.12s)\n",
      "Gen 507 :   avg: 0.752  -  max: 0.760 (0.12s)\n",
      "Gen 508 :   avg: 0.748  -  max: 0.760 (0.11s)\n",
      "Gen 509 :   avg: 0.752  -  max: 0.760 (0.11s)\n",
      "Gen 510 :   avg: 0.751  -  max: 0.760 (0.11s)\n",
      "Gen 511 :   avg: 0.751  -  max: 0.760 (0.12s)\n",
      "Gen 512 :   avg: 0.750  -  max: 0.760 (0.12s)\n",
      "Gen 513 :   avg: 0.751  -  max: 0.760 (0.11s)\n",
      "Gen 514 :   avg: 0.751  -  max: 0.760 (0.12s)\n",
      "Gen 515 :   avg: 0.751  -  max: 0.760 (0.11s)\n",
      "Gen 516 :   avg: 0.751  -  max: 0.760 (0.11s)\n",
      "Gen 517 :   avg: 0.749  -  max: 0.760 (0.12s)\n",
      "Gen 518 :   avg: 0.749  -  max: 0.760 (0.12s)\n",
      "Gen 519 :   avg: 0.750  -  max: 0.760 (0.11s)\n",
      "Gen 520 :   avg: 0.751  -  max: 0.760 (0.12s)\n",
      "Gen 521 :   avg: 0.750  -  max: 0.760 (0.11s)\n",
      "Gen 522 :   avg: 0.747  -  max: 0.760 (0.12s)\n",
      "Gen 523 :   avg: 0.750  -  max: 0.760 (0.11s)\n",
      "Gen 524 :   avg: 0.750  -  max: 0.760 (0.11s)\n",
      "Gen 525 :   avg: 0.750  -  max: 0.760 (0.12s)\n",
      "Gen 526 :   avg: 0.749  -  max: 0.763 (0.11s)\n",
      "Gen 527 :   avg: 0.753  -  max: 0.763 (0.11s)\n",
      "Gen 528 :   avg: 0.755  -  max: 0.763 (0.11s)\n",
      "Gen 529 :   avg: 0.754  -  max: 0.763 (0.11s)\n",
      "Gen 530 :   avg: 0.751  -  max: 0.763 (0.12s)\n",
      "Gen 531 :   avg: 0.752  -  max: 0.763 (0.11s)\n",
      "Gen 532 :   avg: 0.756  -  max: 0.763 (0.11s)\n",
      "Gen 533 :   avg: 0.753  -  max: 0.763 (0.12s)\n",
      "Gen 534 :   avg: 0.752  -  max: 0.763 (0.11s)\n",
      "Gen 535 :   avg: 0.751  -  max: 0.763 (0.11s)\n",
      "Gen 536 :   avg: 0.755  -  max: 0.763 (0.11s)\n",
      "Gen 537 :   avg: 0.754  -  max: 0.763 (0.11s)\n",
      "Gen 538 :   avg: 0.753  -  max: 0.763 (0.11s)\n",
      "Gen 539 :   avg: 0.748  -  max: 0.763 (0.12s)\n",
      "Gen 540 :   avg: 0.751  -  max: 0.764 (0.11s)\n",
      "Gen 541 :   avg: 0.754  -  max: 0.764 (0.11s)\n",
      "Gen 542 :   avg: 0.753  -  max: 0.764 (0.12s)\n",
      "Gen 543 :   avg: 0.753  -  max: 0.764 (0.12s)\n",
      "Gen 544 :   avg: 0.753  -  max: 0.764 (0.11s)\n",
      "Gen 545 :   avg: 0.751  -  max: 0.764 (0.12s)\n",
      "Gen 546 :   avg: 0.756  -  max: 0.764 (0.11s)\n",
      "Gen 547 :   avg: 0.754  -  max: 0.764 (0.12s)\n",
      "Gen 548 :   avg: 0.752  -  max: 0.764 (0.13s)\n",
      "Gen 549 :   avg: 0.751  -  max: 0.764 (0.12s)\n",
      "Gen 550 :   avg: 0.754  -  max: 0.764 (0.12s)\n",
      "Gen 551 :   avg: 0.754  -  max: 0.764 (0.12s)\n",
      "Gen 552 :   avg: 0.752  -  max: 0.764 (0.12s)\n",
      "Gen 553 :   avg: 0.756  -  max: 0.764 (0.12s)\n",
      "Gen 554 :   avg: 0.753  -  max: 0.764 (0.12s)\n",
      "Gen 555 :   avg: 0.758  -  max: 0.764 (0.12s)\n",
      "Gen 556 :   avg: 0.754  -  max: 0.764 (0.12s)\n",
      "Gen 557 :   avg: 0.752  -  max: 0.764 (0.12s)\n",
      "Gen 558 :   avg: 0.756  -  max: 0.764 (0.12s)\n",
      "Gen 559 :   avg: 0.756  -  max: 0.764 (0.12s)\n",
      "Gen 560 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 561 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 562 :   avg: 0.757  -  max: 0.766 (0.12s)\n",
      "Gen 563 :   avg: 0.759  -  max: 0.766 (0.12s)\n",
      "Gen 564 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 565 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 566 :   avg: 0.759  -  max: 0.766 (0.12s)\n",
      "Gen 567 :   avg: 0.756  -  max: 0.766 (0.11s)\n",
      "Gen 568 :   avg: 0.758  -  max: 0.766 (0.12s)\n",
      "Gen 569 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 570 :   avg: 0.754  -  max: 0.766 (0.11s)\n",
      "Gen 571 :   avg: 0.753  -  max: 0.766 (0.11s)\n",
      "Gen 572 :   avg: 0.754  -  max: 0.766 (0.11s)\n",
      "Gen 573 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 574 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 575 :   avg: 0.759  -  max: 0.766 (0.11s)\n",
      "Gen 576 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 577 :   avg: 0.756  -  max: 0.766 (0.11s)\n",
      "Gen 578 :   avg: 0.759  -  max: 0.766 (0.11s)\n",
      "Gen 579 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 580 :   avg: 0.753  -  max: 0.766 (0.12s)\n",
      "Gen 581 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 582 :   avg: 0.754  -  max: 0.766 (0.12s)\n",
      "Gen 583 :   avg: 0.758  -  max: 0.766 (0.11s)\n",
      "Gen 584 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 585 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 586 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 587 :   avg: 0.754  -  max: 0.766 (0.11s)\n",
      "Gen 588 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 589 :   avg: 0.754  -  max: 0.766 (0.11s)\n",
      "Gen 590 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 591 :   avg: 0.755  -  max: 0.766 (0.11s)\n",
      "Gen 592 :   avg: 0.756  -  max: 0.766 (0.11s)\n",
      "Gen 593 :   avg: 0.757  -  max: 0.766 (0.12s)\n",
      "Gen 594 :   avg: 0.757  -  max: 0.766 (0.12s)\n",
      "Gen 595 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 596 :   avg: 0.753  -  max: 0.766 (0.11s)\n",
      "Gen 597 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 598 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 599 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 600 :   avg: 0.753  -  max: 0.766 (0.12s)\n",
      "Gen 601 :   avg: 0.757  -  max: 0.766 (0.12s)\n",
      "Gen 602 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 603 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 604 :   avg: 0.752  -  max: 0.766 (0.12s)\n",
      "Gen 605 :   avg: 0.758  -  max: 0.766 (0.12s)\n",
      "Gen 606 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 607 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 608 :   avg: 0.759  -  max: 0.766 (0.11s)\n",
      "Gen 609 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 610 :   avg: 0.754  -  max: 0.766 (0.11s)\n",
      "Gen 611 :   avg: 0.757  -  max: 0.766 (0.11s)\n",
      "Gen 612 :   avg: 0.757  -  max: 0.766 (0.12s)\n",
      "Gen 613 :   avg: 0.756  -  max: 0.766 (0.12s)\n",
      "Gen 614 :   avg: 0.755  -  max: 0.766 (0.12s)\n",
      "Gen 615 :   avg: 0.759  -  max: 0.766 (0.12s)\n",
      "Gen 616 :   avg: 0.758  -  max: 0.766 (0.12s)\n",
      "Gen 617 :   avg: 0.756  -  max: 0.768 (0.12s)\n",
      "Gen 618 :   avg: 0.757  -  max: 0.768 (0.12s)\n",
      "Gen 619 :   avg: 0.754  -  max: 0.768 (0.12s)\n",
      "Gen 620 :   avg: 0.759  -  max: 0.768 (0.12s)\n",
      "Gen 621 :   avg: 0.759  -  max: 0.768 (0.12s)\n",
      "Gen 622 :   avg: 0.757  -  max: 0.768 (0.12s)\n",
      "Gen 623 :   avg: 0.757  -  max: 0.768 (0.12s)\n",
      "Gen 624 :   avg: 0.757  -  max: 0.768 (0.12s)\n",
      "Gen 625 :   avg: 0.754  -  max: 0.768 (0.12s)\n",
      "Gen 626 :   avg: 0.755  -  max: 0.768 (0.12s)\n",
      "Gen 627 :   avg: 0.758  -  max: 0.768 (0.12s)\n",
      "Gen 628 :   avg: 0.757  -  max: 0.768 (0.12s)\n",
      "Gen 629 :   avg: 0.758  -  max: 0.769 (0.12s)\n",
      "Gen 630 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 631 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 632 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 633 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 634 :   avg: 0.758  -  max: 0.769 (0.12s)\n",
      "Gen 635 :   avg: 0.758  -  max: 0.769 (0.12s)\n",
      "Gen 636 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 637 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 638 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 639 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 640 :   avg: 0.757  -  max: 0.769 (0.11s)\n",
      "Gen 641 :   avg: 0.758  -  max: 0.769 (0.12s)\n",
      "Gen 642 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 643 :   avg: 0.757  -  max: 0.769 (0.12s)\n",
      "Gen 644 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 645 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 646 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 647 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 648 :   avg: 0.758  -  max: 0.769 (0.12s)\n",
      "Gen 649 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 650 :   avg: 0.758  -  max: 0.769 (0.12s)\n",
      "Gen 651 :   avg: 0.757  -  max: 0.769 (0.12s)\n",
      "Gen 652 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 653 :   avg: 0.758  -  max: 0.769 (0.11s)\n",
      "Gen 654 :   avg: 0.758  -  max: 0.769 (0.11s)\n",
      "Gen 655 :   avg: 0.759  -  max: 0.769 (0.11s)\n",
      "Gen 656 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 657 :   avg: 0.758  -  max: 0.769 (0.11s)\n",
      "Gen 658 :   avg: 0.758  -  max: 0.769 (0.11s)\n",
      "Gen 659 :   avg: 0.759  -  max: 0.769 (0.12s)\n",
      "Gen 660 :   avg: 0.760  -  max: 0.769 (0.12s)\n",
      "Gen 661 :   avg: 0.759  -  max: 0.772 (0.12s)\n",
      "Gen 662 :   avg: 0.765  -  max: 0.772 (0.12s)\n",
      "Gen 663 :   avg: 0.764  -  max: 0.772 (0.11s)\n",
      "Gen 664 :   avg: 0.760  -  max: 0.772 (0.12s)\n",
      "Gen 665 :   avg: 0.761  -  max: 0.772 (0.12s)\n",
      "Gen 666 :   avg: 0.760  -  max: 0.772 (0.12s)\n",
      "Gen 667 :   avg: 0.766  -  max: 0.772 (0.12s)\n",
      "Gen 668 :   avg: 0.760  -  max: 0.772 (0.12s)\n",
      "Gen 669 :   avg: 0.760  -  max: 0.772 (0.11s)\n",
      "Gen 670 :   avg: 0.764  -  max: 0.772 (0.11s)\n",
      "Gen 671 :   avg: 0.763  -  max: 0.772 (0.12s)\n",
      "Gen 672 :   avg: 0.761  -  max: 0.774 (0.11s)\n",
      "Gen 673 :   avg: 0.769  -  max: 0.774 (0.12s)\n",
      "Gen 674 :   avg: 0.765  -  max: 0.774 (0.12s)\n",
      "Gen 675 :   avg: 0.766  -  max: 0.774 (0.11s)\n",
      "Gen 676 :   avg: 0.765  -  max: 0.774 (0.12s)\n",
      "Gen 677 :   avg: 0.765  -  max: 0.774 (0.12s)\n",
      "Gen 678 :   avg: 0.768  -  max: 0.774 (0.12s)\n",
      "Gen 679 :   avg: 0.767  -  max: 0.774 (0.11s)\n",
      "Gen 680 :   avg: 0.765  -  max: 0.774 (0.12s)\n",
      "Gen 681 :   avg: 0.765  -  max: 0.774 (0.11s)\n",
      "Gen 682 :   avg: 0.766  -  max: 0.774 (0.12s)\n",
      "Gen 683 :   avg: 0.767  -  max: 0.776 (0.12s)\n",
      "Gen 684 :   avg: 0.765  -  max: 0.776 (0.12s)\n",
      "Gen 685 :   avg: 0.766  -  max: 0.776 (0.12s)\n",
      "Gen 686 :   avg: 0.763  -  max: 0.776 (0.12s)\n",
      "Gen 687 :   avg: 0.765  -  max: 0.776 (0.12s)\n",
      "Gen 688 :   avg: 0.768  -  max: 0.776 (0.11s)\n",
      "Gen 689 :   avg: 0.763  -  max: 0.776 (0.12s)\n",
      "Gen 690 :   avg: 0.765  -  max: 0.776 (0.12s)\n",
      "Gen 691 :   avg: 0.765  -  max: 0.776 (0.12s)\n",
      "Gen 692 :   avg: 0.765  -  max: 0.776 (0.12s)\n",
      "Gen 693 :   avg: 0.768  -  max: 0.776 (0.12s)\n",
      "Gen 694 :   avg: 0.769  -  max: 0.776 (0.12s)\n",
      "Gen 695 :   avg: 0.769  -  max: 0.776 (0.12s)\n",
      "Gen 696 :   avg: 0.768  -  max: 0.776 (0.12s)\n",
      "Gen 697 :   avg: 0.769  -  max: 0.776 (0.12s)\n",
      "Gen 698 :   avg: 0.767  -  max: 0.776 (0.12s)\n",
      "Gen 699 :   avg: 0.765  -  max: 0.776 (0.13s)\n",
      "Gen 700 :   avg: 0.768  -  max: 0.776 (0.12s)\n",
      "Gen 701 :   avg: 0.769  -  max: 0.776 (0.12s)\n",
      "Gen 702 :   avg: 0.768  -  max: 0.776 (0.12s)\n",
      "Gen 703 :   avg: 0.768  -  max: 0.776 (0.12s)\n",
      "Gen 704 :   avg: 0.767  -  max: 0.776 (0.12s)\n",
      "Gen 705 :   avg: 0.768  -  max: 0.776 (0.12s)\n",
      "Gen 706 :   avg: 0.772  -  max: 0.777 (0.12s)\n",
      "Gen 707 :   avg: 0.768  -  max: 0.779 (0.12s)\n",
      "Gen 708 :   avg: 0.770  -  max: 0.779 (0.12s)\n",
      "Gen 709 :   avg: 0.769  -  max: 0.779 (0.12s)\n",
      "Gen 710 :   avg: 0.773  -  max: 0.779 (0.12s)\n",
      "Gen 711 :   avg: 0.772  -  max: 0.779 (0.12s)\n",
      "Gen 712 :   avg: 0.770  -  max: 0.779 (0.13s)\n",
      "Gen 713 :   avg: 0.769  -  max: 0.779 (0.12s)\n",
      "Gen 714 :   avg: 0.774  -  max: 0.782 (0.13s)\n",
      "Gen 715 :   avg: 0.779  -  max: 0.783 (0.13s)\n",
      "Gen 716 :   avg: 0.776  -  max: 0.783 (0.12s)\n",
      "Gen 717 :   avg: 0.776  -  max: 0.784 (0.12s)\n",
      "Gen 718 :   avg: 0.775  -  max: 0.784 (0.12s)\n",
      "Gen 719 :   avg: 0.773  -  max: 0.784 (0.12s)\n",
      "Gen 720 :   avg: 0.776  -  max: 0.784 (0.12s)\n",
      "Gen 721 :   avg: 0.776  -  max: 0.784 (0.12s)\n",
      "Gen 722 :   avg: 0.774  -  max: 0.784 (0.12s)\n",
      "Gen 723 :   avg: 0.775  -  max: 0.785 (0.12s)\n",
      "Gen 724 :   avg: 0.778  -  max: 0.786 (0.12s)\n",
      "Gen 725 :   avg: 0.779  -  max: 0.787 (0.12s)\n",
      "Gen 726 :   avg: 0.779  -  max: 0.787 (0.12s)\n",
      "Gen 727 :   avg: 0.778  -  max: 0.787 (0.12s)\n",
      "Gen 728 :   avg: 0.780  -  max: 0.787 (0.12s)\n",
      "Gen 729 :   avg: 0.780  -  max: 0.787 (0.12s)\n",
      "Gen 730 :   avg: 0.779  -  max: 0.787 (0.12s)\n",
      "Gen 731 :   avg: 0.779  -  max: 0.787 (0.12s)\n",
      "Gen 732 :   avg: 0.782  -  max: 0.787 (0.12s)\n",
      "Gen 733 :   avg: 0.779  -  max: 0.787 (0.12s)\n",
      "Gen 734 :   avg: 0.780  -  max: 0.787 (0.12s)\n",
      "Gen 735 :   avg: 0.781  -  max: 0.787 (0.12s)\n",
      "Gen 736 :   avg: 0.781  -  max: 0.787 (0.12s)\n",
      "Gen 737 :   avg: 0.783  -  max: 0.787 (0.12s)\n",
      "Gen 738 :   avg: 0.782  -  max: 0.787 (0.12s)\n",
      "Gen 739 :   avg: 0.782  -  max: 0.788 (0.12s)\n",
      "Gen 740 :   avg: 0.781  -  max: 0.788 (0.12s)\n",
      "Gen 741 :   avg: 0.781  -  max: 0.788 (0.12s)\n",
      "Gen 742 :   avg: 0.783  -  max: 0.789 (0.12s)\n",
      "Gen 743 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 744 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 745 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 746 :   avg: 0.783  -  max: 0.789 (0.12s)\n",
      "Gen 747 :   avg: 0.781  -  max: 0.789 (0.12s)\n",
      "Gen 748 :   avg: 0.778  -  max: 0.789 (0.12s)\n",
      "Gen 749 :   avg: 0.782  -  max: 0.789 (0.12s)\n",
      "Gen 750 :   avg: 0.783  -  max: 0.789 (0.12s)\n",
      "Gen 751 :   avg: 0.778  -  max: 0.789 (0.12s)\n",
      "Gen 752 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 753 :   avg: 0.783  -  max: 0.789 (0.13s)\n",
      "Gen 754 :   avg: 0.779  -  max: 0.789 (0.12s)\n",
      "Gen 755 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 756 :   avg: 0.779  -  max: 0.789 (0.12s)\n",
      "Gen 757 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 758 :   avg: 0.781  -  max: 0.789 (0.12s)\n",
      "Gen 759 :   avg: 0.781  -  max: 0.789 (0.12s)\n",
      "Gen 760 :   avg: 0.781  -  max: 0.789 (0.12s)\n",
      "Gen 761 :   avg: 0.781  -  max: 0.789 (0.12s)\n",
      "Gen 762 :   avg: 0.779  -  max: 0.789 (0.13s)\n",
      "Gen 763 :   avg: 0.779  -  max: 0.789 (0.12s)\n",
      "Gen 764 :   avg: 0.780  -  max: 0.789 (0.12s)\n",
      "Gen 765 :   avg: 0.783  -  max: 0.789 (0.12s)\n",
      "Gen 766 :   avg: 0.782  -  max: 0.791 (0.12s)\n",
      "Gen 767 :   avg: 0.784  -  max: 0.791 (0.12s)\n",
      "Gen 768 :   avg: 0.785  -  max: 0.791 (0.13s)\n",
      "Gen 769 :   avg: 0.783  -  max: 0.791 (0.13s)\n",
      "Gen 770 :   avg: 0.782  -  max: 0.791 (0.12s)\n",
      "Gen 771 :   avg: 0.782  -  max: 0.791 (0.13s)\n",
      "Gen 772 :   avg: 0.785  -  max: 0.791 (0.12s)\n",
      "Gen 773 :   avg: 0.784  -  max: 0.791 (0.12s)\n",
      "Gen 774 :   avg: 0.782  -  max: 0.791 (0.12s)\n",
      "Gen 775 :   avg: 0.784  -  max: 0.791 (0.12s)\n",
      "Gen 776 :   avg: 0.782  -  max: 0.791 (0.12s)\n",
      "Gen 777 :   avg: 0.785  -  max: 0.791 (0.12s)\n",
      "Gen 778 :   avg: 0.786  -  max: 0.791 (0.12s)\n",
      "Gen 779 :   avg: 0.783  -  max: 0.791 (0.12s)\n",
      "Gen 780 :   avg: 0.784  -  max: 0.791 (0.12s)\n",
      "Gen 781 :   avg: 0.783  -  max: 0.791 (0.12s)\n",
      "Gen 782 :   avg: 0.785  -  max: 0.791 (0.12s)\n",
      "Gen 783 :   avg: 0.786  -  max: 0.792 (0.12s)\n",
      "Gen 784 :   avg: 0.785  -  max: 0.792 (0.12s)\n",
      "Gen 785 :   avg: 0.786  -  max: 0.792 (0.12s)\n",
      "Gen 786 :   avg: 0.785  -  max: 0.792 (0.12s)\n",
      "Gen 787 :   avg: 0.785  -  max: 0.792 (0.12s)\n",
      "Gen 788 :   avg: 0.786  -  max: 0.792 (0.12s)\n",
      "Gen 789 :   avg: 0.782  -  max: 0.792 (0.12s)\n",
      "Gen 790 :   avg: 0.781  -  max: 0.792 (0.12s)\n",
      "Gen 791 :   avg: 0.782  -  max: 0.792 (0.12s)\n",
      "Gen 792 :   avg: 0.784  -  max: 0.792 (0.12s)\n",
      "Gen 793 :   avg: 0.785  -  max: 0.792 (0.12s)\n",
      "Gen 794 :   avg: 0.785  -  max: 0.793 (0.12s)\n",
      "Gen 795 :   avg: 0.786  -  max: 0.793 (0.12s)\n",
      "Gen 796 :   avg: 0.785  -  max: 0.793 (0.12s)\n",
      "Gen 797 :   avg: 0.785  -  max: 0.793 (0.12s)\n",
      "Gen 798 :   avg: 0.785  -  max: 0.793 (0.12s)\n",
      "Gen 799 :   avg: 0.786  -  max: 0.793 (0.12s)\n",
      "Gen 800 :   avg: 0.785  -  max: 0.793 (0.12s)\n",
      "Gen 801 :   avg: 0.786  -  max: 0.794 (0.12s)\n",
      "Gen 802 :   avg: 0.785  -  max: 0.794 (0.12s)\n",
      "Gen 803 :   avg: 0.786  -  max: 0.794 (0.12s)\n",
      "Gen 804 :   avg: 0.785  -  max: 0.794 (0.12s)\n",
      "Gen 805 :   avg: 0.786  -  max: 0.794 (0.12s)\n",
      "Gen 806 :   avg: 0.784  -  max: 0.794 (0.13s)\n",
      "Gen 807 :   avg: 0.788  -  max: 0.794 (0.11s)\n",
      "Gen 808 :   avg: 0.785  -  max: 0.794 (0.12s)\n",
      "Gen 809 :   avg: 0.786  -  max: 0.795 (0.12s)\n",
      "Gen 810 :   avg: 0.785  -  max: 0.795 (0.12s)\n",
      "Gen 811 :   avg: 0.785  -  max: 0.795 (0.12s)\n",
      "Gen 812 :   avg: 0.787  -  max: 0.795 (0.12s)\n",
      "Gen 813 :   avg: 0.787  -  max: 0.796 (0.11s)\n",
      "Gen 814 :   avg: 0.790  -  max: 0.796 (0.12s)\n",
      "Gen 815 :   avg: 0.789  -  max: 0.796 (0.11s)\n",
      "Gen 816 :   avg: 0.790  -  max: 0.796 (0.11s)\n",
      "Gen 817 :   avg: 0.789  -  max: 0.796 (0.12s)\n",
      "Gen 818 :   avg: 0.789  -  max: 0.796 (0.12s)\n",
      "Gen 819 :   avg: 0.789  -  max: 0.796 (0.12s)\n",
      "Gen 820 :   avg: 0.788  -  max: 0.796 (0.12s)\n",
      "Gen 821 :   avg: 0.790  -  max: 0.796 (0.12s)\n",
      "Gen 822 :   avg: 0.790  -  max: 0.796 (0.12s)\n",
      "Gen 823 :   avg: 0.790  -  max: 0.796 (0.12s)\n",
      "Gen 824 :   avg: 0.790  -  max: 0.797 (0.12s)\n",
      "Gen 825 :   avg: 0.791  -  max: 0.797 (0.12s)\n",
      "Gen 826 :   avg: 0.790  -  max: 0.797 (0.12s)\n",
      "Gen 827 :   avg: 0.790  -  max: 0.797 (0.12s)\n",
      "Gen 828 :   avg: 0.789  -  max: 0.797 (0.12s)\n",
      "Gen 829 :   avg: 0.786  -  max: 0.797 (0.12s)\n",
      "Gen 830 :   avg: 0.788  -  max: 0.797 (0.12s)\n",
      "Gen 831 :   avg: 0.792  -  max: 0.798 (0.12s)\n",
      "Gen 832 :   avg: 0.792  -  max: 0.799 (0.3s)\n",
      "Gen 833 :   avg: 0.792  -  max: 0.799 (0.12s)\n",
      "Gen 834 :   avg: 0.792  -  max: 0.800 (0.12s)\n",
      "Gen 835 :   avg: 0.796  -  max: 0.802 (0.12s)\n",
      "Gen 836 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 837 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 838 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 839 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 840 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 841 :   avg: 0.796  -  max: 0.802 (0.12s)\n",
      "Gen 842 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 843 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 844 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 845 :   avg: 0.795  -  max: 0.802 (0.11s)\n",
      "Gen 846 :   avg: 0.796  -  max: 0.802 (0.11s)\n",
      "Gen 847 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 848 :   avg: 0.794  -  max: 0.802 (0.11s)\n",
      "Gen 849 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 850 :   avg: 0.795  -  max: 0.802 (0.11s)\n",
      "Gen 851 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 852 :   avg: 0.797  -  max: 0.802 (0.12s)\n",
      "Gen 853 :   avg: 0.792  -  max: 0.802 (0.12s)\n",
      "Gen 854 :   avg: 0.793  -  max: 0.802 (0.11s)\n",
      "Gen 855 :   avg: 0.796  -  max: 0.802 (0.12s)\n",
      "Gen 856 :   avg: 0.796  -  max: 0.802 (0.12s)\n",
      "Gen 857 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 858 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 859 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 860 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 861 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 862 :   avg: 0.795  -  max: 0.802 (0.11s)\n",
      "Gen 863 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 864 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 865 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 866 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 867 :   avg: 0.792  -  max: 0.802 (0.12s)\n",
      "Gen 868 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 869 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 870 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 871 :   avg: 0.795  -  max: 0.802 (0.11s)\n",
      "Gen 872 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 873 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 874 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 875 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 876 :   avg: 0.796  -  max: 0.802 (0.11s)\n",
      "Gen 877 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 878 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 879 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 880 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 881 :   avg: 0.792  -  max: 0.802 (0.12s)\n",
      "Gen 882 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 883 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 884 :   avg: 0.794  -  max: 0.802 (0.11s)\n",
      "Gen 885 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 886 :   avg: 0.792  -  max: 0.802 (0.12s)\n",
      "Gen 887 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 888 :   avg: 0.797  -  max: 0.802 (0.12s)\n",
      "Gen 889 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 890 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 891 :   avg: 0.792  -  max: 0.802 (0.12s)\n",
      "Gen 892 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 893 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 894 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 895 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 896 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 897 :   avg: 0.794  -  max: 0.802 (0.13s)\n",
      "Gen 898 :   avg: 0.796  -  max: 0.802 (0.12s)\n",
      "Gen 899 :   avg: 0.794  -  max: 0.802 (0.13s)\n",
      "Gen 900 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 901 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 902 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 903 :   avg: 0.794  -  max: 0.802 (0.13s)\n",
      "Gen 904 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 905 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 906 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 907 :   avg: 0.793  -  max: 0.802 (0.12s)\n",
      "Gen 908 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 909 :   avg: 0.791  -  max: 0.802 (0.12s)\n",
      "Gen 910 :   avg: 0.792  -  max: 0.802 (0.12s)\n",
      "Gen 911 :   avg: 0.794  -  max: 0.802 (0.12s)\n",
      "Gen 912 :   avg: 0.795  -  max: 0.802 (0.12s)\n",
      "Gen 913 :   avg: 0.794  -  max: 0.803 (0.12s)\n",
      "Gen 914 :   avg: 0.797  -  max: 0.803 (0.11s)\n",
      "Gen 915 :   avg: 0.794  -  max: 0.803 (0.12s)\n",
      "Gen 916 :   avg: 0.794  -  max: 0.803 (0.11s)\n",
      "Gen 917 :   avg: 0.796  -  max: 0.803 (0.12s)\n",
      "Gen 918 :   avg: 0.797  -  max: 0.803 (0.11s)\n",
      "Gen 919 :   avg: 0.793  -  max: 0.803 (0.12s)\n",
      "Gen 920 :   avg: 0.794  -  max: 0.803 (0.11s)\n",
      "Gen 921 :   avg: 0.792  -  max: 0.803 (0.11s)\n",
      "Gen 922 :   avg: 0.796  -  max: 0.803 (0.11s)\n",
      "Gen 923 :   avg: 0.793  -  max: 0.803 (0.11s)\n",
      "Gen 924 :   avg: 0.794  -  max: 0.803 (0.12s)\n",
      "Gen 925 :   avg: 0.796  -  max: 0.803 (0.12s)\n",
      "Gen 926 :   avg: 0.794  -  max: 0.803 (0.12s)\n",
      "Gen 927 :   avg: 0.796  -  max: 0.804 (0.12s)\n",
      "Gen 928 :   avg: 0.796  -  max: 0.804 (0.12s)\n",
      "Gen 929 :   avg: 0.794  -  max: 0.804 (0.12s)\n",
      "Gen 930 :   avg: 0.797  -  max: 0.804 (0.11s)\n",
      "Gen 931 :   avg: 0.797  -  max: 0.804 (0.12s)\n",
      "Gen 932 :   avg: 0.797  -  max: 0.804 (0.12s)\n",
      "Gen 933 :   avg: 0.794  -  max: 0.804 (0.11s)\n",
      "Gen 934 :   avg: 0.797  -  max: 0.804 (0.12s)\n",
      "Gen 935 :   avg: 0.798  -  max: 0.804 (0.11s)\n",
      "Gen 936 :   avg: 0.795  -  max: 0.804 (0.11s)\n",
      "Gen 937 :   avg: 0.797  -  max: 0.804 (0.12s)\n",
      "Gen 938 :   avg: 0.795  -  max: 0.804 (0.12s)\n",
      "Gen 939 :   avg: 0.796  -  max: 0.804 (0.12s)\n",
      "Gen 940 :   avg: 0.794  -  max: 0.804 (0.12s)\n",
      "Gen 941 :   avg: 0.795  -  max: 0.804 (0.11s)\n",
      "Gen 942 :   avg: 0.794  -  max: 0.804 (0.11s)\n",
      "Gen 943 :   avg: 0.795  -  max: 0.804 (0.12s)\n",
      "Gen 944 :   avg: 0.795  -  max: 0.804 (0.12s)\n",
      "Gen 945 :   avg: 0.793  -  max: 0.804 (0.12s)\n",
      "Gen 946 :   avg: 0.796  -  max: 0.804 (0.12s)\n",
      "Gen 947 :   avg: 0.794  -  max: 0.804 (0.12s)\n",
      "Gen 948 :   avg: 0.795  -  max: 0.804 (0.11s)\n",
      "Gen 949 :   avg: 0.794  -  max: 0.804 (0.11s)\n",
      "Gen 950 :   avg: 0.796  -  max: 0.804 (0.11s)\n",
      "Gen 951 :   avg: 0.795  -  max: 0.804 (0.12s)\n",
      "Gen 952 :   avg: 0.800  -  max: 0.804 (0.12s)\n",
      "Gen 953 :   avg: 0.799  -  max: 0.805 (0.12s)\n",
      "Gen 954 :   avg: 0.796  -  max: 0.805 (0.12s)\n",
      "Gen 955 :   avg: 0.796  -  max: 0.805 (0.12s)\n",
      "Gen 956 :   avg: 0.798  -  max: 0.805 (0.12s)\n",
      "Gen 957 :   avg: 0.797  -  max: 0.805 (0.12s)\n",
      "Gen 958 :   avg: 0.800  -  max: 0.806 (0.12s)\n",
      "Gen 959 :   avg: 0.800  -  max: 0.806 (0.12s)\n",
      "Gen 960 :   avg: 0.802  -  max: 0.807 (0.12s)\n",
      "Gen 961 :   avg: 0.803  -  max: 0.809 (0.12s)\n",
      "Gen 962 :   avg: 0.800  -  max: 0.809 (0.12s)\n",
      "Gen 963 :   avg: 0.802  -  max: 0.809 (0.12s)\n",
      "Gen 964 :   avg: 0.802  -  max: 0.809 (0.12s)\n",
      "Gen 965 :   avg: 0.802  -  max: 0.809 (0.12s)\n",
      "Gen 966 :   avg: 0.803  -  max: 0.809 (0.12s)\n",
      "Gen 967 :   avg: 0.803  -  max: 0.809 (0.12s)\n",
      "Gen 968 :   avg: 0.800  -  max: 0.809 (0.12s)\n",
      "Gen 969 :   avg: 0.803  -  max: 0.809 (0.12s)\n",
      "Gen 970 :   avg: 0.803  -  max: 0.809 (0.12s)\n",
      "Gen 971 :   avg: 0.802  -  max: 0.810 (0.13s)\n",
      "Gen 972 :   avg: 0.804  -  max: 0.810 (0.12s)\n",
      "Gen 973 :   avg: 0.804  -  max: 0.812 (0.12s)\n",
      "Gen 974 :   avg: 0.807  -  max: 0.812 (0.12s)\n",
      "Gen 975 :   avg: 0.805  -  max: 0.812 (0.12s)\n",
      "Gen 976 :   avg: 0.806  -  max: 0.812 (0.12s)\n",
      "Gen 977 :   avg: 0.807  -  max: 0.812 (0.12s)\n",
      "Gen 978 :   avg: 0.805  -  max: 0.812 (0.12s)\n",
      "Gen 979 :   avg: 0.806  -  max: 0.812 (0.12s)\n",
      "Gen 980 :   avg: 0.805  -  max: 0.812 (0.12s)\n",
      "Gen 981 :   avg: 0.807  -  max: 0.812 (0.12s)\n",
      "Gen 982 :   avg: 0.805  -  max: 0.812 (0.11s)\n",
      "Gen 983 :   avg: 0.806  -  max: 0.812 (0.12s)\n",
      "Gen 984 :   avg: 0.806  -  max: 0.812 (0.12s)\n",
      "Gen 985 :   avg: 0.804  -  max: 0.812 (0.12s)\n",
      "Gen 986 :   avg: 0.807  -  max: 0.813 (0.11s)\n",
      "Gen 987 :   avg: 0.806  -  max: 0.813 (0.12s)\n",
      "Gen 988 :   avg: 0.805  -  max: 0.813 (0.12s)\n",
      "Gen 989 :   avg: 0.806  -  max: 0.813 (0.12s)\n",
      "Gen 990 :   avg: 0.806  -  max: 0.813 (0.12s)\n",
      "Gen 991 :   avg: 0.807  -  max: 0.813 (0.12s)\n",
      "Gen 992 :   avg: 0.807  -  max: 0.813 (0.11s)\n",
      "Gen 993 :   avg: 0.806  -  max: 0.813 (0.12s)\n",
      "Gen 994 :   avg: 0.809  -  max: 0.813 (0.12s)\n",
      "Gen 995 :   avg: 0.808  -  max: 0.813 (0.11s)\n",
      "Gen 996 :   avg: 0.805  -  max: 0.813 (0.12s)\n",
      "Gen 997 :   avg: 0.808  -  max: 0.813 (0.12s)\n",
      "Gen 998 :   avg: 0.809  -  max: 0.813 (0.11s)\n",
      "Gen 999 :   avg: 0.808  -  max: 0.813 (0.11s)\n",
      "Finished training (117.99)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Model\n",
      "==========================================================================================\n",
      "Convolution (relu) + Pooling   (in=(28, 28, 1), out=(13, 13, 6))        #Params: 54\n",
      "Flatten ()                     (in=(13, 13, 6), out=1014)               #Params: 0\n",
      "Linear (softmax)               (in=1014, out=10)                        #Params: 10151\n",
      "==========================================================================================\n",
      "Total params: 10205\n",
      "Accuracy: 0.813\n",
      "\n",
      "CPU times: total: 1min 59s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# initial population\n",
    "population = Population(size=POPULATION_SIZE,n_survivors=SURVIVORS)\n",
    "\n",
    "# future populations\n",
    "population.train(GENERATIONS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot confusion matrix**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\n",
      "0 : 0.935 %\n",
      "1 : 0.952 %\n",
      "2 : 0.777 %\n",
      "3 : 0.79 %\n",
      "4 : 0.816 %\n",
      "5 : 0.629 %\n",
      "6 : 0.863 %\n",
      "7 : 0.784 %\n",
      "8 : 0.739 %\n",
      "9 : 0.814 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = tf.math.confusion_matrix(labels=y_true, predictions=np.argmax(population.elite(X_test), axis=1))\n",
    "plt.imshow(confusion_matrix, cmap='Greys')   # y-axis: y_true, x-axis: y_pred\n",
    "plt.colorbar()\n",
    "#print(confusion_matrix)\n",
    "\n",
    "# precision for each class\n",
    "print('Precision:')\n",
    "precision = lambda row, i: round(row[i] / sum(row), 3)  # precision for each class\n",
    "for i, row in enumerate(confusion_matrix.numpy()):\n",
    "    print(i, ':', precision(row, i), '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot filters**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 6 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "filters = population.elite.kernel1\n",
    "n_filters = filters.shape[-1]\n",
    "plt.figure()\n",
    "for filter_idx in range(n_filters):\n",
    "    plt.subplot(math.ceil(n_filters**0.5), math.floor(n_filters**0.5), filter_idx + 1)\n",
    "    plt.imshow(filters[:, :, :, filter_idx], cmap='Greys')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}